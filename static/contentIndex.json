{"blog/A-Psalm-for-the-Wild-Built":{"slug":"blog/A-Psalm-for-the-Wild-Built","filePath":"blog/A Psalm for the Wild-Built.md","title":"A Psalm for the Wild-Built","links":[],"tags":["book-review"],"content":"Becky Chambers, 2021, a Science Fiction/Solarpunk Novella\nThe story is set in a post-AI utopia, where the robots, upon gaining consciousness, fled into the wild, and humanity rebuilt its society with a reverence to nature, including technology. The society is built where machines can only be tools for humans, but cannot replace tasks. There is a kind of natural objectivism that is explored, represented through the religion that is constructed—agreed to exist by the robot that is encountered. Harmony with the forces of nature, including consciousness, is prioritized above all, and the society is made around that, which brings them to the utopia.\nKey to the world is that all characters are completely unalienated from their work. No one works for others; the professions are all traders, tea makers, monks, teachers, doctors, artists, farmers, etc. Everyone is completely connected to the products of their labor, and everyone has complete autonomy over what they do or make. There is a social aspect to all the work that is done. Even for the robots, they all have key specializations from which they derive meaning, even if it is only to observe the world. A very “from each according to ability, to each according to their need” vibe is present: “They work the farmland in Haydale, and it produces a lot of food. We had a surplus. A surplus has to be shared.”\nThe story explored is that of someone trying to find fulfilment in this world. Really just some core struggles that come up when trying to get to the top of Maslow’s hierarchy. Finding purpose is hard, even when you’re good at things and make the world better or make those around you happier. The robot’s existence, and what it blatantly states at the end, is that ultimately fulfillment can only be found through the abandonment of purpose as an end-goal at all, and to simply exist as a creature in nature. The book proposes that this is an idea to consider once all our needs are met.\nThe book reveres nature; it spends a lot of time describing the beauty of different scenes. As part of that, it explores the contradictions in nature stemming from the conflict of existence—needing organisms to die to sustain others, and the general cycle of life. Respecting this is, in some sense, “good,” as the robots with their supreme intellect choose to recycle parts into new individuals rather than repairing old ones and submit themselves to death, as they want to be in accordance with nature. The fact that humans, even in their utopia, divide the land between human settlements and wilds—comprising half the land area and avoided by humans—is seen as a blindness to the fact that humans are just animals like all others. It proposes Winn’s paradox: “the ecosystem as a whole needs its participants to act with restraint in order to avoid collapse, but the participants themselves have no inbuilt mechanism to encourage such behavior […] other than fear, which is a feeling you want to avoid or stop at all costs.” Underlying this is the idea that the harmony that has been achieved in the society, however imperfect, was attained through the process of creating and losing the robots who chose to leave—a key historical event in this world. The existence, and vague moral or real fear underlying the consciousness in the robots, has somehow kept the humans in check.\nI like the general approach of the book to describe the kind of internal conflicts people might face as a way of normalizing the anarchist utopia that this world envisions, with the backdrop of meaningful autonomous work, an inclusive society, and helping others. The normalization is a very powerful technique: a cozy, adorable story is created to ease you into these broader political/philosophical ideas, it’s very neat. I dislike that being in accordance with nature is presented as the prime directive to reach this utopia, as opposed to the well-being of people as the ultimate goal in and of itself—likely why I’m sure killing and eating animals is seen as morally fine in this world, as a naturalistic fallacy. As a small nitpick, the fact that money (“pebs”) exists in this utopian society is unimaginative and kind of contradictory to the whole vibe of everyone just doing things to help each other and existing well. People get things for free all the time in this world. It’s only mentioned twice in passing and could have easily been left out.\nI think the question of whether we need technology to reach utopia is left up to debate in this framework—we don’t need it in practice, but we might need its threat in order for us to engage with our animal instincts and live in accordance with nature.\n3⁄5","date":"2024-11-13T00:00:00.000Z"},"blog/A-look-at-the-Bitcoin-P2P-network-topology":{"slug":"blog/A-look-at-the-Bitcoin-P2P-network-topology","filePath":"blog/A look at the Bitcoin P2P network topology.md","title":"A look at the Bitcoin P2P network topology","links":["bitcoin","bitcoin/"],"tags":["math"],"content":"If you read the original whitepaper for Bitcoin, it states that the point of a blockchain is to solve the double-spend problem for a digital currency in the case of a P2P network.\nThe double-spend problem\nFor a physical currency, we can track who has money by who holds it in their possession. They can only spend a coin once because they have to give it to someone. But how do we deal with this online? If I have 20 bucks, and I send you 20 bucks, that’s fine. But what if I also sent Bob 20 bucks, or anyone else for that matter? What happens in this situation? Which transaction, if any, is valid? This is known as the double-spend problem.\na centralised authority solution\nUsually, we have a bank that records our quantity of money. When we spend money the quantity goes down, not allowing money to be spent if the quantity runs out. This prevents anyone from spending more money than they have, solving the double-spend problem. In practice, if Alice wants to send money to Bob, Alice tells her bank to transfer money to Bob, her bank tells Bob’s bank, and both banks adjust the quantities in their accounts. Note here that this system requires both Alice and Bob to trust both Alice’s bank and Bob’s bank, and for the banks to trust each other. There may also be fees associated with this service.\na decentralised solution\nBut what if we don’t want to have to introduce trust into the system? We want to not rely on any specific 3rd party, but if someone sends you money how can you trust that the money hasn’t been spent before. The blockchain introduced with Bitcoin, based on proof-of-work, was the first successful solution to this problem. It requires users to have computers that communicate directly with other computers on the network, rather than going through any trusted third party. This is called a peer-to-peer (P2P) network. There are countless resources out there for understanding how Bitcoin works, but a thesis by Itsi Weinstock and this video by Grant Sanderson are excellent ones.\nBitcoin architecture\nIn the Bitcoin P2P network, your computer isn’t directly linked to every other computer, rather a small group of them. Think of it as a social network where each computer, or node, is connected to only their friends, or peers, who they communicate with. There are around 10,000 nodes on the Bitcoin network. Each node is connected to 8-12 other nodes on average according to a snapshot taken in the seminal Coinscope paper published in 2015 which was the first to study the Bitcoin P2P network topology, which nodes are connected to which.\nBuilt into Bitcoin is a notion of anonymity. When transactions are sent through the network, they refer to money moving between Bitcoin addresses, or wallets. However, when nodes refer to other nodes, they do so through their IP addresses. The idea is that by separating your IP and Bitcoin addresses into two separate things, it’ll be hard to track which wallets belong to which computers. So Bitcoin is ‘anonymous’ because you don’t know which computers are sending and receiving money, only wallets which are abstract and not necessarily linked to the real world. The process of deanonymising Bitcoin is then about correlating Bitcoin addresses with IP addresses, so we know which computers send which transactions.\nFinding the topology\nIn 2014, it was discovered that knowledge of the P2P network topology could be used to deanonymise Bitcoin. This triggered an arms race between academic researchers on one side and Bitcoin Core developers on the other, as to how techniques could be developed to find the topology vs how they could be patched out of effectiveness. This has been going for some years with various papers (here, here, here, here — by far the funniest method — and here) which can be seen summarised in my thesis.\nInterestingly, they all focus on how transactions propagate throughout the network. I found a few different ways to classify them which would be useful. They either actively send new transactions into the network, or passively receive transactions already in the network. They either focus on specific nodes to learn their connections or try to infer the whole network at one time. And they either use idiosyncrasies of the Bitcoin protocol to expose weaknesses, or they employ a statistical framework.\nFortunately, the first paper gave a snapshot of the network in 2015 that let us challenge some assumptions. Notably, they found that the network did not resemble a “random graph” (there is some notion of purposeful structure), and they found that around 2% of all nodes generated over 75% of all the blocks.\nLooking at the papers, what really needs to be developed is a passive and statistical approach. One that just infers based on timing measurements of transactions already on the network. That way no one needs to spend money on transactions and it’s far harder to patch out.","date":"2019-12-12T00:00:00.000Z"},"blog/Cooking-Techniques":{"slug":"blog/Cooking-Techniques","filePath":"blog/Cooking Techniques.md","title":"Cooking Techniques","links":[],"tags":["recipes"],"content":"Cooking onions quickly (the baking powder trick)\nSauteing mushrooms efficiently\nCooking beans well (the teabag trick)\nCauliflower cooking effects\nEmulsifying soup with bread\nUse the long thing eggplants in most applications! Big ones just for baba ganoush.","date":"2019-12-15T00:00:00.000Z"},"blog/Designing-Good-AI-Agent-Systems-with-Evaluations":{"slug":"blog/Designing-Good-AI-Agent-Systems-with-Evaluations","filePath":"blog/Designing Good AI Agent Systems with Evaluations.md","title":"Designing Good AI Agent Systems with Evaluations","links":[],"tags":["math"],"content":"Intro concepts\nEvals and the data flywheel are what will make or break AI products\nEvals are the base infrastructure to do future work on prompt engineering, few-shot learning, RAG, and fine-tuning.\nWe make systems better by looking at A LOT of data. The point of evals is to make us look at the right places so we can make our agents better.\nThrough this process, we force ourselves to strictly define what are pass and fail conditions for each eval. Human experts should be included at every step of the process. They provide ground truth and craft what the criteria for the evals should be. Eval judges should converge to human experts.\nThere are many types of evals, but you should use judges\nJudges are when we use LLMs themselves to perform the evals. This is in contrast to humans doing the evals, or traditional ML techniques that can be based on things like embedding similarity to references.\nJudges let you move extremely fast, and allow scaling to performing evals on all AI activity, adding to the flywheel.\nJudges are not a perfect solution, they have downsides around bias, not capturing complexity, and not having measurable uncertainty. LLMs eating their own tails (aka LLMception) are discussed in Who Validates the Validators?. We should consider other types of evals down the line.\nHere is a critical discussion of the approach. Upsides, downsides, theoretical and evidence-based evaluations. Critical Analysis of the ‘LLM-as-a-Judge’ Approach\nClassifier judges and Comparison judges\nFor subjective outcomes (tone, persuasiveness, conciseness), you will get better consistency and resolution with evals that compare which is better between two options rather than direct scoring. This is true for both humans and LLM evals. We can simulate a lot of data and use judges to do pairwise comparisons to create ELO scores or similar to determine which agents are better.\nI am making an assumption that we care more about objective outcomes first, which is why I’m focusing on binary classification judges. But different use cases may require more thought on doing pairwise comparison judges first.\n\nBuilding effective binary classification judges\nPrinciples\n\nHuman experts should be deeply integrated into every project\nEvaluation criteria have to be expanded and refined as you go\nUse binary evaluation wherever possible. Evals seem fairly useless without this, and it forces us to make actionable changes (rather than scoring or a 1-5 scale). Make binary judgments specific, and have more of them, rather than ambiguous catch-alls.\nTurn every problem into an eval/test\nUse the most powerful model we can afford. Eval logic is hard. (except for guardrails, which must be latency sensitive)\n\n\n\nRemove ALL friction from looking at data.\nKeep it simple. Don’t buy fancy LLM tools. Use what you have first.\nYou are doing it wrong if you aren’t looking at lots of data.\nDon’t rely on generic evaluation frameworks to measure the quality of your AI. Instead, create an evaluation system specific to your problem.\nWrite lots of tests and frequently update them.\nLLMs can be used to unblock the creation of an eval system. Examples include using an LLM to:\n\nGenerate test cases and write assertions\nGenerate synthetic data\nCritique and label data etc.\n\n\nRe-use your eval infrastructure for debugging and fine-tuning.\n\n\nAn order of how to go about it\n1. Unit Evals\n\nBasic expected functionality should be made into discretized unit evals\n\n(calling functions, not returning UUIDs in response, etc.)\n\n\nUse LLMs to create synthetic conversations to run against these tests\nSet failure based on a certain % that don’t pass the tests. Not as simple as pass/fail on everything.\nRun and track tests regularly\n\n2. Tracing\nYou must remove all friction from the process of looking at data\nMaybe something like www.langchain.com/langsmith (does not require langchain)\nEvery agent should have custom tracing and a UI to view it:\n\ncustom for each agent\ndistinguishing between synthetic and real data\nfilters to navigate examples\nAbility to tag examples as good/bad responses for each eval\n\n3. Create a Synthetic dataset\n\n\nIt is absolutely fine and desirable to start with synthetic data before rolling things out\n\n\nWhat you generally want is conversations between simulated users and your agents\n\n\nWe want high diversity. A framework we can use to generate the dataset is to use LLMs to generate conversations that are combinations of:\n\nFeature\nScenario\nPersona\n\n\n\nConsult with the expert to make sure that the simulated users are realistic, and refine them.\n\n\nWe will augment this with real data as we collect it, and we can use real data to help refine the synthetic data.\n\n\nThe amount of data to generate is the amount where we are confident we won’t see new failure modes.\n\n\nNote: Replace or augment synthetic data with real data as systems are deployed. We can use real data as examples to get better synthetic data\n4. Get the human expert to review the data\n\npass/fail on specific criteria only\nreasoning for why it passes/fails. Here are examples of what we’re looking for\n\nMost importantly, the critique should be detailed enough so that you can use it in a few-shot prompt for an LLM judge. In other words, it should be detailed enough that a new employee could understand it. Being too terse is a common mistake.\n\nStart with ~30 examples, go from there until you don’t see more failure modes\n\n5. Implement a judge, and converge it to human-eval\nNOTE: Human experts don’t always agree, maybe expect 85% convergence between humans and use this as the benchmark\n\nDo this low tech, just cycle through prompts manually and see how auto and human compare\nInclude some few-shot examples\nGet both the LLM and Expert to provide explicit reasoning, forcing reconsideration of the eval\n\nAlign AI to human. Calibrate human to AI. Repeat.\nThe key insight is that aligning AI to human preferences is only half the battle. To build effective evals, we must also calibrate human criteria to AI output.\nMany teams make the mistake of crafting elaborate eval criteria without first looking at the data. It’s like theorizing about user experience and defects from the ivory tower, without doing error analysis. From Who Validates the Validators: “It is impossible to completely determine evaluation criteria prior to human judging of LLM outputs.“\nThis leads to two types of bad criteria. First, irrelevant criteria that are a waste of time, such as generic metrics (e.g., helpfulness) or very low probability defects (e.g., grammar, spelling). Second, unrealistic, unattainable criteria that the technology isn’t ready for, such as autonomous agents back in 2023. Either way, teams squander effort that would have been better invested in evaluating actual defects that occur with moderate frequency.\nNOTE: Human experts are not consistent. Even after they spend time aligning, they are not consistent. There are many things like context, fatigue, or personal biases to consider. Using one expert as ground truth may amplify noise. Strategies here include using multiple experts, or doing some test on human expert consistency.\n6. Test the judge against the larger (synthetic/real) dataset, and do targeted improvements\n\nFix agents with informed prioritization\nBecause of the feature, scenario, persona categorization, we can identify specifically where the agents are failing\nWe can also classify the types of errors and sort by that\n\n\n7. Deploy. More data. More judges\n\nRun evals on all real data that we collect\nCreate more synthetic data if it seems necessary to find edge cases\nCreate more judges as necessary for new evals\n\nHere’s the flow diagram. Note that the numbers here don’t map exactly to what I have above.\n\nAfter you are done with this, promising directions\n\nPairwise comparison judges to build out ELO scores for more subjective evals e.g. tone, conciseness, conversation-flow, etc.\nFinetuning - Fine-tuning is best for learning syntax, style, and rules, whereas techniques like RAG supply the model with context or up-to-date facts.\nAutomated prompt improvement: e.g. aligneval.com/\nContinual in-context learning. Basically like RAG but injects relevant examples for few-shot learning into the prompt.\nPrompt-caching if we want a lot of examples\nLast response evaluation www.confident-ai.com/blog/llm-chatbot-evaluation-explained-top-chatbot-evaluation-metrics-and-testing-techniques\nG-Eval www.confident-ai.com/blog/llm-evaluation-metrics-everything-you-need-for-llm-evaluation\n\nSome Useful Readings\nYour AI Product Needs Evals\nCreating a LLM-as-a-Judge That Drives Business Results\nEvaluating the Effectiveness of LLM-Evaluators (aka LLM-as-Judge)","date":"2025-03-05T00:00:00.000Z"},"blog/Dimension-reduction-using-equality-constraints-on-a-simplex-constrained-linear-system":{"slug":"blog/Dimension-reduction-using-equality-constraints-on-a-simplex-constrained-linear-system","filePath":"blog/Dimension reduction using equality constraints on a simplex-constrained linear system.md","title":"Dimension reduction using equality constraints on a simplex-constrained linear system","links":[],"tags":["math"],"content":"This page is to distill an algebra slog I’ve been doing that is useful for some optimization spaces. Less dimensions is usually better, and we can use equality constraints to express some parameters and combinations of others, and essentially work in a lower dimensional space. Maybe there’s a better way to use this using a more general linear algebra approach but the algebra for this cases was doable enough in a short time.\nSay we are working in some linear system, in my case I’ve been doing optimization where the objective function is determined experimentally and not analytically.\nIn the base case we have continuous real parameters x_i,\\ i\\in\\mathcal{I}, with lower and upper bounds for each, L_i and U_i. And usually we’ll have some linear constraint.\n\\begin{align}\n\n\\sum_\\mathcal{I}c_ix_i &amp;\\le C \\newline\n\nL_i \\le x_i &amp; \\le U_i \\qquad i\\in\\mathcal{I}\n\n\\end{align}\nThe simplex constraint\nNow let’s introduce the simplex constraint, the sum of parameters equals some total T.\n\\begin{align}\n\n\\sum_\\mathcal{I} x_i &amp;= T\\newline\n\n\\sum_\\mathcal{I}c_ix_i &amp;\\le C\\newline\n\nL_i \\le x_i &amp;\\le U_i \\qquad i\\in\\mathcal{I}\n\n\\end{align}\nLet’s select a parameter to remove from the search space, x_1. Using (3), we can express it as a function of the other parameters,\n\\begin{align}\n\nx_1 &amp;= T - \\sum_{\\mathcal{I}\\setminus 1}x_i\n\n\\end{align}\nSubbing this value into (4) and the i=1 constraint of (5), we get the new space to work in:\n\\begin{align}\n\n\\sum_{\\mathcal{I}\\setminus 1}(c_i-c_1)x_i &amp;\\le C - c_1T\\newline\n\nT - U_1 \\le \\sum_{\\mathcal{I}\\setminus 1}x_i &amp;\\le T - L_1\\newline\n\nL_i \\le x_i &amp;\\le U_i \\qquad i\\in\\mathcal{I}\\setminus 1\n\n\\end{align}\nThe simplex constraint and one additional linear equality constraint\nNow let’s introduce a linear equality constraint.\n\\begin{align}\n\n\\sum_\\mathcal{I} x_i &amp;= T\\newline\n\n\\sum_\\mathcal{I}a_ix_i &amp;= A\\newline\n\n\\sum_\\mathcal{I}c_ix_i &amp;\\le C\\newline\n\nL_i \\le x_i &amp;\\le U_i \\qquad i\\in\\mathcal{I}\n\n\\end{align}\nUsing equations (10) and (11), we can extract parameters x_1 and x_2 as a function of the other parameters. Not for the following to work, we require that a_1\\ne a_2.\n\\begin{align}\n\nx_1 &amp;= \\frac{a_2T - A}{a_2-a_1} - \\sum_{\\mathcal{I}\\setminus 1,2}\\frac{a_2-a_i}{a_2-a_1}x_i\\newline\n\nx_2 &amp;= \\frac{A-a_1T}{a_2-a_1} - \\sum_{\\mathcal{I}\\setminus 1,2}\\frac{a_i-a_1}{a_2-a_1}x_i\\newline\n\n\\end{align}\nSubbing this value into (12) and the i=1,2 constraints of (13), we get the new space to work in:\n\\begin{align}\n\n\\sum_{\\mathcal{I}\\setminus 1,2}\\left(c_i-\\frac{c_1a_2 - c_2a_1 - (c_1-c_2)a_i}{a_2-a_1}\\right)x_i &amp;\\le C - \\frac{(c_1a_2 - c_2a_1)T - (c_1-c_2)a_i}{a_2-a_1}\\newline\n\n\\frac{a_2T - A}{a_2-a_1}-U_1 \\le \\sum_{\\mathcal{I}\\setminus 1,2}\\frac{a_2-a_i}{a_2-a_1}x_i &amp;\\le \\frac{a_2T - A}{a_2-a_1}-L_1\\newline\n\n\\frac{A - a_1T}{a_2-a_1}-U_2 \\le \\sum_{\\mathcal{I}\\setminus 1,2}\\frac{a_i-a_1}{a_2-a_1}x_i &amp;\\le \\frac{A - a_1T}{a_2-a_1}-L_2\\newline\n\nL_i \\le x_i &amp;\\le U_i \\qquad i\\in\\mathcal{I}\\setminus 1,2\n\n\\end{align}\nThe simplex constraint and two additional linear equality constraints\nLet’s have two equality constraints.\n\\begin{align}\n\n\\sum_\\mathcal{I} x_i &amp;= T\\newline\n\n\\sum_\\mathcal{I}a_ix_i &amp;= A\\newline\n\n\\sum_\\mathcal{I}b_ix_i &amp;= B\\newline\n\n\\sum_\\mathcal{I}c_ix_i &amp;\\le C\\newline\n\nL_i \\le x_i &amp;\\le U_i \\qquad i\\in\\mathcal{I}\n\n\\end{align}\nThis can get away from us very quickly. But if we are wise and want to avoid too much algebra, we can carefully select things so that\n\\begin{align}\n\na_1&amp;=0\\newline\n\na_2&amp;\\ne0\\newline\n\nb_1,b_2&amp;=0\\newline\n\nb_3&amp;\\ne0\n\n\\end{align}\nThen things fall out nicely from (20), (21), and (22). We can express x_1,x_2,x_3 explicitly in terms of the other parameters.\n\\begin{align}\n\nx_1 &amp;= T - \\frac{Ab_3 + (a_2-a_3)B}{a_2b_3} - \\sum_{\\mathcal{I}\\setminus 1,2,3}\\left(1-\\frac{a_ib_3 + (a_2-a_3)b_i}{a_2b_3}\\right)x_i\\newline\n\nx_2 &amp;= \\frac{Ab_3 - a_3B}{a_2b_3} - \\sum_{\\mathcal{I}\\setminus 1,2,3}\\frac{a_ib_3 - a_3b_i}{a_2b_3}x_i\\newline\n\nx_3 &amp;= \\frac{B}{b_3} - \\sum_{\\mathcal{I}\\setminus 1,2,3}\\frac{b_i}{b_3}x_i\\newline\n\n\\end{align}\nSubbing these values into (23) and the i=1,2,3 constraints for (24) we get the new space to work in\n\\begin{align}\n\n\\sum_{\\mathcal{I}\\setminus 1,2,3} \\left[ c_i - c_1 - \\frac{c_2-c_1}{a_2}a_i - \\frac{a_2c_3 - a_3c_2 - (a_2-a_3)c_1}{a_2b_3}b_i\\right]x_i &amp;\\le C - c_1T - \\frac{c_2-c_1}{a_2}A - \\frac{a_2c_3 - a_3c_2 - (a_2-a_3)c_1}{a_2b_3}B \\newline\n\nT - \\frac{1}{a_2}A - \\frac{a_2-a_3}{a_2b_3}B - U_1 \\le \\sum_{\\mathcal{I}\\setminus 1,2,3} \\left(1 - \\frac{1}{a_2}a_i - \\frac{a_2-a_3}{a_2b_3}b_i\\right)x_i &amp; \\le T - \\frac{1}{a_2}A - \\frac{a_2-a_3}{a_2b_3}B - L_1\\newline\n\nAb_3 - a_3B - a_2b_3U_2 \\le \\sum_{\\mathcal{I}\\setminus 1,2,3}\\left(a_ib_3 - a_3b_i\\right)x_i &amp;\\le Ab_3 - a_3B - a_2b_3L_2\\newline\n\nB - b_3U_3 \\le \\sum_{\\mathcal{I}\\setminus 1,2,3} b_ix_i &amp;\\le B - b_3L_3\\newline\n\nL_i \\le x_i &amp;\\le U_i \\qquad i\\in\\mathcal{I}\\setminus 1,2,3\n\n\\end{align}","date":"2024-03-14T00:00:00.000Z"},"blog/Finding-all-vertices-of-a-convex-polytope-defined-by-a-high-dimensional-linear-system":{"slug":"blog/Finding-all-vertices-of-a-convex-polytope-defined-by-a-high-dimensional-linear-system","filePath":"blog/Finding all vertices of a convex polytope defined by a high-dimensional linear system.md","title":"Finding all vertices of a convex polytope defined by a high-dimensional linear system","links":[],"tags":["math"],"content":"I was dealing with an optimization problem in n positive dimensions with m linear constraints, and it occured to me it would be useful to find all the vertices of the polytope created by the constraints. My optimization method required some rejection sampling, so finding the tightest bounding box would make things more efficient, and I could get the lower and upper bounds for each dimension by enumerating all the vertices and finding the highest and lowest values.\nNow, unfortunately, an upper bound for the number of vertices is given by the number of ways that n of the m constraint and n variable=0 hyperplanes intersect, {m+n \\choose n}. Constraints here also include upper and (nonzero) lower bounds. In my problem, I had 11 dimensions and 23 constraints, so 286,097,760 basic solutions. In most cases though, the vast majority of these intersections will not fall within the feasible space.\nA bad solution: check each vertex\nOne way to find all vertices (feasible solutions) of the polytope, is to enumerate all intersection points, check if they are feasible, and return all the feasible ones as. This is, of course, very dumb. For my dummy problem on my laptop it predicted it would take about an hour and I got bored, it won’t scale at all.\nAn actual solution: depth-first search using simplex-inspired methods\nIf we have a linear objective function over the space, then the simplex method is a way to traverse vertices (feasible solutions) in a greedy way that will eventually end up at the optimal vertex. Now we don’t have an objective function, but we can steal the ideas to do the vertex traversal.\nFinding feasible solutions\nLet’s notate that our linear system is described as Ax \\le b, where A is our m \\times n matrix encoding the inequalities.\nThe way this works is to associate a new slack variable s_j with each of the m constraints, where s_j = [b - Ax]_{j}. So we now have m+n variables. We choose a basis set of m variables, and set the remaining n variables to 0, this corresponds to a vertex of those n intersecting hyperplanes. You can get the values for the m basis variables by constructing a new matrix (tableau) that appends [A | I_{m\\times m} | b], and doing a row reduction that sets your m basis variables to the identity matrix, and reading the right-most &quot;b&quot; column.\nNow we just need to worry about feasibility. This will occur if we have at least n variables equal to 0, and the remaining m variables being non-negative, so either the original variables or the slack is positive, so we exist in the constrained space. If we assume our starting point is already feasible, then there are n variables we can move into the basis, swapping for a basic variable, to traverse to a new vertex. This means increasing a variable from 0 to a nonnegative value. We can increase the value until the first basic variable becomes 0 (after which we will leave the feasible region). We pick that one as the basic variable to pivot out, and we do that swap. So for each vertex, we can construct n pairs of variables to switch in/out of the basis.\nCool, now we just need an initial feasible point. We can do this by pretending we have a linear objective function (e.g. just sum the value of the variables), and finding the “optimal” solution with an existing solver.\nDepth-first search\nWe could do a number of search algorithms, but the most efficient one will incorporate the fact that doing a change of basis between neighbors is MUCH cheaper than doing a new row reduction for each new feasible set of basis variables. So each time we explore a neighbor, we pass in the preceeding tableau and do a muich smaller change. If we consider the vertices as nodes in a graph, with neighboring vertices having edges between them, then we can conduct a breadth/depth first search across the entire graph until we’ve hit everything.\nThe problem with breadth-first is that we might need to keep a large number of these tableaus in memory depending on the size of the system. Depth-first gives us the opportunity to explore a path til exhausted then start chucking them out, potentially reducing the maximum size of the queue.\nHowever, we can expect the structure of this graph to be highly connected, each vertex has n neighbors, so it’s quite a regular, interconnected shape. It would be easy to construct a path that visits almost all nodes. So we call a vertex “discovered” if we know that it exists, and “visited” if we traverse to it, find it’s solution and discover its neighbors. So this is a kind of hybrid depth/breadth search. traversal to a vertex is done from the first vertex that discovers it.\ntraverse_vertex(vertex):\n\nfind values for variables at vertex\nfor each neighbor\n\nif neighbor is undiscovered\n\nadd neighbor to discovered set\nadd neighbor to traversal list for this vertex\n\n\n\n\nfor each neighbor in traversal list\n\ntraverse_vertex(neighbor)\n\n\n\nWe just need to pass in a root vertex we can get from a solver, then we’re good to go. We can escape some extra time complexity issues by ensuring we use hash maps where possible, e.g. checking against the set of discovered vertices.\nTesting it out\nI ran it on a n=11 variables, m=23 linear constraints problem. There are 286,097,759 possible vertices, of which only a tiny minority should be feasible. This algorithm was able to find all 4352 feasible vertices in 18 seconds on my M2 macbook.\nWe can inspect the run through logging the depth, number of discovered nodes, and number of nodes in the queue at each new vertex traversal. Here it is for this problem. Code for getting the plot is at the end.\n\nPython Code\nimport numpy as np\nimport pandas as pd\nfrom scipy.optimize import linprog\nimport sympy as sp\nfrom copy import copy\n \n \nclass CornerFinder:\n    def __init__(self, A, b):\n        self.A = A\n        self.b = b\n        self.m, self.n = A.shape\n        self.variables = [\n            &quot;x&quot;+str(i+1).zfill(len(str(self.n))) for i in range(self.n)\n        ] + [\n            &quot;s&quot;+str(i+1).zfill(len(str(self.m))) for i in range(self.m)\n        ]\n        \n        self.vertices=[]\n        self.discovered = set()\n        self.vertex_df = pd.DataFrame()\n        \n        self.queue_length = 1\n        self.depth = 0\n        \n        self.queue_length_list = []\n        self.depth_list = []\n        self.discovered_list = []\n        \n    def find_corners(self):\n        root_tableau = self._get_root_tableau()\n        root_basic_variables = frozenset(root_tableau.index)\n        self.discovered.add(root_basic_variables)\n        self._traverse_vertex(root_tableau)\n        self.vertex_df = pd.DataFrame(\n            np.array(self.vertices)[:,:self.n], \n            columns=self.variables[:self.n]\n        )\n \n    def _get_root_tableau(self):\n        &quot;&quot;&quot;\n        Artificially set a linear objective function to find a feasible solution\n        &quot;&quot;&quot;\n        A = self.A\n        b = self.b\n        m = self.m\n        n = self.n\n        variables = self.variables\n \n        result = linprog(c=[-1 for _ in range(n)], A_ub=A.tolist(), b_ub=b.tolist())\n        slack_values = (b - A @ result.x).round(10)\n        basic_variables = [\n            x for i, x in enumerate(variables[:n]) if result.x[i] &gt; 0\n        ] + [\n            s for i, s in enumerate(variables[n:]) if slack_values[i] &gt; 0\n        ]\n        nonbasic_variables = [v for v in variables if v not in basic_variables]\n \n        tableau = np.zeros((m, n + m + 1))\n        tableau[:, :n] = A\n        tableau[:, n:n + m] = np.eye(m)\n        tableau[:, -1] = b\n \n        tableau = pd.DataFrame(tableau, columns=variables+[&quot;b&quot;])\n        tableau = tableau[basic_variables + nonbasic_variables +[&quot;b&quot;]]\n \n        reduced_matrix, basis = sp.Matrix(tableau).rref()\n        tableau = pd.DataFrame(\n            reduced_matrix.tolist(), \n            columns=tableau.columns, \n        ).astype(float)\n        \n        # redefine in case there are less than m variables in the basis\n        basic_variables = tableau.columns[list(basis)]\n        tableau.index = basic_variables\n        tableau = tableau.loc[[v for v in variables if v in basic_variables],variables+[&quot;b&quot;]]\n \n        return tableau\n \n    def _get_neighbor_pivots(self, tableau):\n        &quot;&quot;&quot;\n        Get the n pairs of variables to pivot in/out of the basis\n        &quot;&quot;&quot;\n        basic_variables = [v for v in self.variables if v in tableau.index]\n        nonbasic_variables = [v for v in self.variables if v not in tableau.index]\n \n        neighbor_pivots = []\n \n        for nonbasic_variable in nonbasic_variables:\n            ratios = tableau[&#039;b&#039;].div(tableau[nonbasic_variable].clip(0))\n            basic_variable = ratios.idxmin()\n            neighbor_pivots.append((basic_variable, nonbasic_variable))\n \n        return neighbor_pivots\n \n    def _get_solution(self, tableau):\n        &quot;&quot;&quot;\n        Read the values of the variables from the given tableau\n        &quot;&quot;&quot;\n        solution = []\n        for v in self.variables:\n            if v in tableau.index:\n                solution.append(tableau.loc[v, &quot;b&quot;])\n            else:\n                solution.append(0)\n        return solution\n \n    def _traverse_vertex(self, tableau):\n        &quot;&quot;&quot;\n        Recursive depth-first search to explore all vertices\n        &quot;&quot;&quot;\n        # increase depth level for logging\n        self.depth += 1\n        \n        # log depth, queue length, and discovered vertices\n        self.depth_list.append(self.depth)\n        self.queue_length_list.append(self.queue_length)\n        self.discovered_list.append(len(self.discovered))\n        \n        # log solution\n        solution = self._get_solution(tableau)\n        self.vertices.append(solution)\n        \n        # remove from queue\n        self.queue_length -= 1\n        \n        # display progress\n        print(\n            f&quot;vertices explored/discovered: {len(self.vertices)}/{len(self.discovered)}&quot;, \n            f&quot;depth: {self.depth}&quot;,\n            f&quot;queue length: {self.queue_length}&quot;,\n            &quot;\\t\\t\\t\\t&quot;,\n            end=&quot;\\r&quot;\n        )\n \n        # get pivot pairs of variables to all feasible neighbors\n        neighbor_pivots = self._get_neighbor_pivots(tableau)\n        \n        # check which neighbors are undiscovered\n        undiscovered_neighbor_pivots = []\n        for pivot_variables in neighbor_pivots:\n \n            # construct basic variable set\n            bv = pivot_variables[0]\n            nbv = pivot_variables[1]\n \n            basic_variables = [v for v in self.variables if v in tableau.index]\n            basic_variables.remove(bv)\n            basic_variables.append(nbv)\n            basic_variables = frozenset(basic_variables)\n            \n \n            # check if set has been visisted\n            if basic_variables in self.discovered:\n                continue\n            \n            # mark them as discovered and add to traversal responsibility for this vertex\n            self.discovered.add(basic_variables)\n            undiscovered_neighbor_pivots.append(pivot_variables)\n                        \n        # add all undiscovered vertices to queue\n        self.queue_length += len(undiscovered_neighbor_pivots)\n        \n        for pivot_variables in undiscovered_neighbor_pivots:            \n            # copy tableau\n            neighbor_tableau = tableau.copy()\n            \n            bv = pivot_variables[0]\n            nbv = pivot_variables[1]\n            \n            # pivot to create new tableau\n            pivot = neighbor_tableau.loc[bv, nbv]\n            pivot_row = neighbor_tableau.loc[bv]\n            pivot_row /= pivot\n \n            for name, row in neighbor_tableau.iterrows():\n                if name == bv:\n                    continue\n                row -= row[nbv] * pivot_row\n \n            # rename indexes for the change in basis\n            neighbor_tableau = neighbor_tableau.rename(index={bv: nbv})\n \n            # order to make look nice\n            neighbor_tableau = neighbor_tableau.loc[\n                [v for v in self.variables if v in neighbor_tableau.index]\n            ]\n            \n            # recursively visit neighbor\n            self._traverse_vertex(neighbor_tableau)\n        \n        # reduce depth at end of exploring this vertex\n        self.depth -= 1\n# Let&#039;s try it out. Ax &lt;= b\nA = np.array([\n    [2, 1], \n    [1, 1], \n    [0, 1], \n    [-1, -1], \n    [-1, -2], \n    [1,-1], \n    [-5, 1], \n    [-1, 0]\n])\nb = np.array([10, 8, 4, -2, -3, 2, -6, -1.6])\n \ncf = CornerFinder(A, b)\ncf.find_corners()\nprint(cf.vertex_df)\n \n         x1        x2\n0  3.000000  4.000000\n1  2.000000  4.000000\n2  1.600000  2.000000\n3  1.600000  0.700000\n4  2.333333  0.333333\n5  4.000000  2.000000\nAnd if you want to print it out the plot as above\nimport matplotlib.pyplot as plt\n \nplt.plot(cf.depth_list, label=&quot;depth&quot;)\nplt.plot(cf.queue_length_list, label=&quot;queue length&quot;)\nplt.plot(cf.discovered_list, label=&quot;vertices discovered&quot;)\nplt.xlabel(&quot;vertices explored&quot;)\nplt.ylabel(&quot;vertices&quot;)\nplt.legend()","date":"2024-04-04T00:00:00.000Z"},"blog/How-to-get-into-tea":{"slug":"blog/How-to-get-into-tea","filePath":"blog/How to get into tea.md","title":"How to get into tea","links":["reddit.com/r/tea","tea-notes"],"tags":[],"content":"Why tea?\nTea is extremely cheap and extremely artisinal. You can become a sophisticant while paying very little. There are very few things in the world like this.\nIf you have a caffeine habit you can swap it in for that. A regular tea session is about 5-8g of loose leaf tea which is as much or more caffeine than a double shot of coffee.\nThe popularity and history of tea has led it down countless winding roads that mean there is a way too much variety for you to explore. The ubiquitousness in parts of the world is exactly what makes it both interesting and cheap. You will pay between 1-4 for a tea session. This is starting to be cheaper than good coffee when you make it at home.\nWhat you should do\n1. Only buy samplers\nIt is the most fun to maximize for variety, at least at the start. Each tea session is ~6g so just buy that much of each and change the tea you’re drinking every day.\nI recommend buying white2tea minis. They are great quality, and beautiful objects. You will get great joy from drinking these teas. Keep in mind they specialize in pu’er and white teas. You will need to look elsewhere to really explore other kinds like green, oolong, and black. Check out the tea subreddit for recommendations.\nTake notes as you go, like I do here: 🍃 Tea Notes\n2. Buy equipment\nYou should be making tea Gongfu style. You may be used to Western style where you brew ~2g of tea in ~400g water for ~3 minutes. With Gongfu it’s ~6g tea in ~100g water for 5-20s brews, and you do multiple on them. Gongfu is the far better way to do it if you’re taste-maxing. You get far more intensity and notes out of the tea.\nI usually sit at my desk while working and make a new brew every 5 minutes while I’m working. It’s extremely quick and fun.\nIt does require some equipment\n\n  \n\n#### Thermos\nIf you have a thermos, you don&#039;t need to keep going back to the kettle. This is necessary for making gongfu practical.\n#### Tiny teapot\nYou want to aim for ~100g of water. \nIn China they use a gaiwan, literally a cup with a lid, or Yixing teapots. In Japan they have teapots (kyusus) and teapots without handles (houhins). You can find a gaiwan online for extremely cheap. I bought a vintage houhin on ebay because it was beautiful.\nJust pick something, it probably won’t be your last if you get into it. If you buy something without a handle just make sure to use a rag when handling it because it gets hot with all the boiling water.\nSmall pitcher\nYou brew for like 10s then pour it out. So you need something to pour it into\nCup\nThe smaller the better. You could probably use a mug as a pitcher and just drink out of that. But it’s much fancier when you have small cups, and then you can share too if you have multiple.\nOptionals\nVariable Temperature Kettle: You need less than boiling water for some teas like greens and yellows. But you can get away by just waiting for water to cool a bit. Also you can just brew oolongs at boiling temperature, you’ll be fine.\nTray: to carry all your stuff around the house\nHow to brew\n\nBoil water and pour in thermos\nPut tea in vessel\nPour water on tea and close lid\nWait 10s\nPour it out into your pitcher\nPour into cups and drink\nRepeat\n\nWith each tea you’ll probably dial in how long to brew between 5-20s and usually you increase the brew time as you go.\nNOTE FOR DRAGON BALLS: With the minis like from white2tea minis, they come in pressed balls. It takes some time for water to saturate to the inner layers because of the tightness and geometry. In this case, do the first brew for 20s, pour it out, then wait with the lid on for like 2 minutes for the water to saturate, before continuing like normal.","date":"2025-09-12T00:00:00.000Z"},"blog/Intro-to-Bayesian-Optimization-1.-Optimization-Intuitions":{"slug":"blog/Intro-to-Bayesian-Optimization-1.-Optimization-Intuitions","filePath":"blog/Intro to Bayesian Optimization 1. Optimization Intuitions.md","title":"Intro to Bayesian Optimization 1. Optimization Intuitions","links":["blog/Intro-to-Bayesian-Optimization-2.-The-Bayesian-Optimization-Framework","blog/Intro-to-Bayesian-Optimization-3.-Intro-to-Bayesian-Statistics","blog/Intro-to-Bayesian-Optimization-4.-Gaussian-Processes"],"tags":["math"],"content":"This is the first part in my Intro to Bayesian Optimization\n\nOptimization Intuitions\nThe Bayesian Optimization Framework\nIntro to Bayesian Statistics\nGaussian Processes\n\nWe often want to answer questions like: “What quantity of each parameter will give us the best results?” These parameters could be the ingredients of a cookie or the best hyperparameters for tuning a machine learning algorithm. In our context, that might be questions like: how much of some ingredients (or maybe heat or time or pH) will give us the best results on some assay? We might also have experiments with extremely noisy measurements: for example asking people how they rate the taste of something.\nTraditionally we may define a set of experiments by picking a range of parameters, collecting the data, and then analyzing it to come to some conclusion. However, if the experiments are run iteratively or in batches, rather than all in parallel, then we can learn the best way to conduct the experiment by picking parameters that will give us the most new information at every step. Bayesian Optimization provides both a way to find the best combination of parameters, and a method that tells us how to best collect samples in a very efficient way; so we either get more information from the same number of experiments, or the same information with less experimenting.\nThere are many approaches to optimization that suit different experimental setups; where Bayesian Optimization shines is in black-box situations where sampling is expensive and iterative. That is,\n\nwe don’t have a complete theory for how the parameters affect the outcome (there is no exact function that we know),\neach evaluation of parameters takes up a lot of time/resources (e.g. training a machine learning model for a week, running an experiment that takes a few hours, or even the full process of creating a product)\niterative; we repeat conducting an experiment, seeing the results, and then making choices about the next experiment. As opposed to running all experiments in parallel.\n\nWe’ll go through 4 sections\n\nOptimization intuitions\nThe Bayesian Optimization framework\nIntro to Bayesian statistics: Bayesian Linear Regression as an example\nGaussian Processes\n\nGlossary\nDon’t worry, we’ll cover all of these.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntermdefinitionblack boxa process that we don’t understand, but we can measure the inputs and outputs to gain understandingoptimizationfinding the point of x and value of f that maximize or minimize some function f(x)\\max_{x}f(x)the maximum value of some function f you can get by varying x\\arg\\max_{x}f(x)the value of x that maximizes some function fsamplesome combination of variables that you decide to run an experiment on (or evaluate a function at)sample/search spaceall possible combination of variablessearch methodthe method by which you decide to select samples for your experimentgrid searcha search method where you sample in even increments across your variablesrandom searcha search method where each variable is chosen (uniformly) randomly independently from the othersexplorationsearching in regions of the sample space that haven’t been visited before to increase informationexploitationsearching in regions of the sample space that you think will give you the best results according to your existing informationacquisition functiona function that tells you how much useful information you get from sampling at any given point in your search space in order to get to the optimal value, balancing exploration with exploitationexpected valuethe theoretical mean for some random eventlikelihood distribution$p(\\mathbf{y}prior distributionp(\\beta): your belief of the probability distribution of some parameters \\beta in the absense of any observed dataposterior distribution$p(\\betaconfidence interval(probability for the interval) for a given fixed parameter \\beta, an interval that \\alpha proportion of the time would contain the parameter if many experiments were run $$\\text{interval }[a,b]\\quad\\text{drawn once from a distribution such that}\\quad P(a &lt; \\beta &lt; bcredible interval(probability for the parameter) an interval with a probability \\alpha that a sample of a parameter \\beta is drawn from the interval $$\\text{interval }[a,b]\\quad\\text{such that}\\quad P(a &lt; \\beta &lt; bupper confidence boundIn a confidence or credible interval, the upper bound for the interval. E.g. in interval [a,b], the value b. If we have a normal distribution with mean \\mu and standard deviation \\sigma, then for some value \\alpha, this will be \\mu + \\lambda \\sigma where \\lambda is calculated from \\alpha. E.g. the 95% upper confidence bound is \\mu + 1.96\\sigmaGaussian ProcessA collection of random variables, such that any finite or infinite subset of them have a joint Normal distribution. A GP\\left(\\mu(x),k(x,x&#039;)\\right) is defined by its mean function \\mu(x) and kernel k(x,x&#039;) which specifies the covariance between variables of the GP\nOptimization is an enormous subsection of mathematics and statistics. For different problems, different approaches work best. In this section we’re going to lay a basic framework of what optimization is and get an understanding of where we might use different optimization methods, so we can get an idea of where Bayesian Optimization is the tool to use.\nIn optimization, we always frame things in terms of functions. For example, we may have some ingredients \\mathbf{x} = [x_1,x_2,\\dots,x_n], where x_i is the quantity of ingredient i. There can be a single or many dimensions of x (many ingredients). We’ll assume only one dimension of x for now (one ingredient), but there can be many. We want to find an optimum (minimum or maximum) of some function f(x). Performing experiments to get the result is referred to as a sample from the function. When we take samples y, we either have no error in our measurements y = f(x), or we have noisy measurements y = f(x) + \\varepsilon where \\varepsilon is some random variable that models the error.\nWe use\n\\begin{equation*}\n\\min_{x} f(x)\n\\end{equation*}\nto refer to the minimum value of f(x) you can get from varying x, and\n\\begin{equation*}\n\\arg\\min_{x} f(x)\n\\end{equation*}\nto refer to the value of x that minimizes f(x). The terminology here is that f is a function of x, and x is an argument of f.\nTypes of optimization\nIf the function is kown, sometimes there is an analytic solution.\n\\begin{equation*}\nf(x) = x^2 - 5x + 6\n\\end{equation*}\nUsing calculus we can find that f(x) is minimized at x = \\frac{5}{2}.\nOr even if there is no analytic solution, e.g. for f(x) = \\text{sin}(x) - x^2, or more complicated examples like the loss of a neural net as a function of its weights and biases, we can find the minimum using gradient methods like Newton’s method or gradient descent.\nBut what if we don’t know the function? Black-box optimization\nThere are countless problems where we don’t have an explicit formula for the function. Think of any experiment you’ve ever conducted, we mostly take samples because we don’t know the underlying function, and we usually either want to model that function to make predictions or find its optimal value.\nThis also occurs frequently in Machine Learning in the area of Hyperparameter Optimization. For instance, using Lasso Regression you can easily find parameters that fit the data the best for a given penalty term, but how do you select the penalty term itself that results in the best fit? There is no explicit relationship, and has to be found with experimentation.\nWhen we can collect a lot of samples, there are techniques like genetic algorithms and simulated annealing we can use. However, in many cases, the function can be very expensive to evaluate, so we need to very quickly converge to a good solution.\nExample: Cookies\nConsider a recipe for a cookie. Let’s say we want to figure out how much sugar we should add (with all the other ingredients in fixed amounts). Too little sugar, and you’ve just made bad bread. Too much, and it can be too sweet, or the sugar can start ruining the texture. We know the limits of no sugar and infinite sugar are undesirable, but we suspect there’s some sweet spot in the middle, or there may even be a few local maxima.\nLet x be the amount of sugar:\n\\begin{equation*}\n\\text{Cookie Deliciousness} = f(x)\n\\end{equation*}\nbut we don’t really know what that function f(x) looks like, we don’t yet have a theoretical understanding of this relationship, we have to rely on sampling, which here would be making a cookie then seeing how good it is. Also in measuring the Cookie Deliciousness, we may need to introduce humans as evaluators of the function, and they are very fickle, so introduce randomness through random variable \\varepsilon into the measurement.\n\\begin{equation*}\n\\text{Cookie Deliciousness} = f(x) + \\varepsilon\n\\end{equation*}\nSampling the function\nLet’s say we don’t have randomness for now. How do we approach the problem of finding the amount of sugar x that maximizes the deliciousness score?\nFirstly, we assume that the function f(x) exists, but we don’t know it.\n\nTrue maximum Deliciousness of 15.833 at x = 7.978\nGrid Search\nMaybe one thing we could do is sample at a whole bunch of points to get the information. Let’s do it evenly spaced. We call this approach Grid Search\n\nMaximum Cookie Deliciousness of 15.288 estimated at x = 8.235\nTrue maximum Deliciousness of 15.833 at x = 7.978\n\nYou can find a good solution, but at what cost. Imagine actually doing these experiments one by one, it’d get boring fast and take up a lot of time.\nIf you sampled in increasing order of amount of sugar, you’d instinctively want to change the size of the steps as you go. As you got to x = 4 you’d know you’re in a bad region, so you’d want to skip ahead to see where things may start getting better.\nThis illustrates some points:\n\nsampling can be expensive, it takes up valuable time and resources\nyour sampling method may vary in efficiency, there may be fewer samples needed to arrive at a good solution\nefficient sampling may be helped with sampling sequentially, maybe there’s a smart way to pick your next sample point based on previous data\n\nMultivariate functions and Random Search\nWhat if we still only want to sample 9 times, but our variable space is 2 dimensional? E.g. we want to measure quantity of sugar and quantity of baking powder\nWhen you specify a grid, you will end up oversampling values of any specific variable, as you will need that value combined with the values of your other variable that are specified by the grid.\nFor most optimization problems that are multivariate, Random Search is a much more efficient way to sample the space. That is, to get a sample point (x,y), sample x and y independently and uniformly from their respective domains.\n\nYou may notice that random search introduces some clustering, which is why methods such as stratified sampling and latin hypercube sampling (LHS) are used. In stratified sampling, the search space is divided into a grid, and one random point in each grid box is selected. In LHS, a finer grid is used, and then a sodoku property is applied, such that you only sample once from each row and column (or the extension in more dimensions).\n\n\t\n\n# Section 1 Summary\nIn optimization, we model our problem as a function. When we don’t know the function (e.g. we don’t have a complete theory for the real-world problem), we can use black-box approaches which rely on sampling the function (e.g. conducting an experiment). However, running experiments can be expensive, so we want to reduce the number of experiments we conduct to get a good result.\nA common choice for black-box optimization is grid search, but this can be very inefficient, especially as we increase our number of parameters. Better choices are random search and related sampling methods that don’t over-sample specific parameter values as much.\nHowever, in all these methods, if we sample the points one at a time or in small batches, can we be more intelligent about our choice in samples?\nIn the next section we will go over Bayesian Optimization as an answer to this question.","date":"2025-09-13T00:00:00.000Z"},"blog/Intro-to-Bayesian-Optimization-2.-The-Bayesian-Optimization-Framework":{"slug":"blog/Intro-to-Bayesian-Optimization-2.-The-Bayesian-Optimization-Framework","filePath":"blog/Intro to Bayesian Optimization 2. The Bayesian Optimization Framework.md","title":"Intro to Bayesian Optimization 2. The Bayesian Optimization Framework","links":["blog/Intro-to-Bayesian-Optimization-1.-Optimization-Intuitions","blog/Intro-to-Bayesian-Optimization-3.-Intro-to-Bayesian-Statistics","blog/Intro-to-Bayesian-Optimization-4.-Gaussian-Processes"],"tags":["math"],"content":"This is the second part in my Intro to Bayesian Optimization\n\nOptimization Intuitions\nThe Bayesian Optimization Framework\nIntro to Bayesian Statistics\nGaussian Processes\n\nRandom Search is widely used, especially when you have a lot of resources you can use in parallel. However, the expected number of samples required to find a good solution can grow with the number of dimensions and size of the “good” section of the sample space.\nBut what if you can’t do things in parallel, and what if sampling is expensive or limited. In practice, we can often only sample our experiments a few times due to resource constraints, so we want to get the most bang for our buck and learn as we go.\nBayesian Optimization offers a very practical way to approach optimization in experimental setups where running an experiment takes significant time and/or resources, and the experiments are done iteratively instead of all in parallel. Compared to grid/random search, think of it as getting the same information in fewer experiments, or getting more information from the same number of experiments.\nWhen do we use BO\n\\begin{equation*}\n\\arg\\max_{x} f(x)\n\\end{equation*}\n\nGlobal optimization: We want to find the global (not local) optimum of some function f (in the bounds that you provide)\nContinuous: there shouldn’t be any discontinuous jumps in f from a small change in x (this is usually an assumption we make if we don’t know a reason why that wouldn’t be the case)\nBlack box: We don’t know the function f, and we don’t know any special features of f like it being linear or concave\nSequential sampling: We can sample f where we choose, and we sample one point at a time (batch methods have been developed as extensions)\nDerivative-free: We cannot sample the first or second-order derivatives of f, otherwise we would choose gradient methods\nExpensive: f is expensive to evaluate at each sample (high computation/high resource/limited samples)\nNot-too-high-dimensional: x is at most 20 dimensional (e.g. we are looking at combinations of at most 20 cookie ingredients). This is more a rule of thumb\nSimple constraints: The bounds of x are simple, we can describe it with a hyper-rectangle or n-dimensional simplex (e.g. the range of each ingredient is independent, or the sum of proportions is 1)\n\nIt turns out this combination of properties appears all the time in experimental design.\nBO strategy\nGiven we don’t know f, we are going to construct a model for the function. We do understand the model, so even if it’s not 100% correct, we can still find its optimal value. Think about it as fitting a regression to the observed points. We will cover this in the next section, but this must be a Bayesian regression, and usually, we use a Gaussian Process. Compare this to the methods in the previous section where none of the approaches involved constructing a model.\nOur goal is then to improve the model as much as we can through information we acquire via sampling. If we have a notion of uncertainty in the model, we can do this intelligently.\nUsing the model, we construct an acquisition function that tells us the next best point to sample. This point won’t just be the point that maximizes the model, it aims to direct our sampling to points that decrease the uncertainty of the model while searching areas that we believe have good solutions.\nNote, in the literature, the name for the model in Bayesian Optimization is a surrogate model. That is because the main application for BO is in machine learning hyperparameter optimization. Our experiments may involve us sampling some point of parameters in the real world, but in hyperparameter optimization the experiment would be training the ML model for a given set of hyperparameters. So surrogate model refers to the cheap to evaluate model of an expensive to train ML model.\nBO Algorithm\n\nStart with some initial sample measurements\nFit a probabilistic model to the data\nCompute the acquisition function based on the model\nFind x^* that maximizes the acquisition function\nSample f(x^*) and add to your data\nIf time/resources are remaining, go to step 2\n\nBO Example\nStarting samples at x=1 and x=9\nThe first suggestion is given at the maximum off the acquisition function, close to our best found solution but further to the right to capture some noise (wide purple area)\n\n3 samples. The acquisition function is moving towards an expected worse section off the search space because it is favoring noise\n\n4 samples. The acquisition function is taking us to an underexplored area of the search space.\n\n5 samples. The exploration has not been fruitful, so it is returning to a higher expected area.\n\nThis continues until we concentrate around the best solution, after 9 samples.\n\nGlobal maximum estimated at x = 7.978 with f(x) = 15.833\nTrue maximum at x = 7.978 with f(x) = 15.833\n\nWe were able to converge to the exact solution fairly quickly! Note how we sampled more in good regions, and have less uncertainty there. We are fine having uncertainty in areas that we don’t think will be as fruitful. This is due to the acquisition function which balances decreasing uncertainty with focusing on good regions. A good acquisition function will direct your optimization to learn only what it needs to in order to be confident in finding a good solution.\nAcquisition function choice\nThere are many ways to pick an acquisition function, but something to keep in mind is that we want to balance exploration — searching for new points to decrease model variance; and exploitation — picking points that we expect will give optimal values.\nExploration\nIf we wanted to maximize exploration of the search space, we would want to pick the point that minimizes our total variance of the model. Here that would just be picking the value of x where the model has the largest standard deviation \\sigma(x). Always pick the point with the widest interval.\n\\begin{equation*}\na(x) = \\sigma(x)\n\\end{equation*}\nAs you can see, it greatly reduces variance in the model but oversamples poor areas, undersamples good areas, and doesn’t converge. This would be a great way to characterise the function, but we are looking to optimize it in as few steps as possible.\nExploitation\nWe use the term exploitation to refer to how greedy a process is in selecting a solution that it thinks optimizes the problem. If we wanted to maximize exploitation, we would want to pick the point that maximizes expected f.\n\\begin{equation*}\na(x) = \\mu(x)\n\\end{equation*}\nHere, we are lucky and we converge quickly to the best solution. However, you can see that many high variance regions of the search space are under-sampled. We could have easily fallen into a local maximum. This is sensitive to the initial sample of points.\nUpper Confidence Bound\nOne intuitive way to balance exploration and exploitation is just to combine both of these terms. We can create an upper confidence bound with some value \\lambda\n\\begin{equation*}\nUCB(x) = \\mu(x) + \\lambda \\sigma(x)\n\\end{equation*}\nand set this as our acquisition function. There are some nice theoretical properties to this function it’s effectiveness can be seen through this intuition about balancing the terms. Note when \\lambda=1.96, the acquisition function is just the upper bound of the 95% interval.\nFor our initial acquisition function, we used UCB with \\lambda=7\nOther popular functions include Probability Improvement, Expected Improvement, Entropy Search, Predictive Entropy Search, and others. You can read about these in the literature.\nSection 2 Recap\nBayesian Optimization is a framework for iteratively sampling a black-box function in order to find the global optimum. We don’t know the function directly, so we construct a model for the function because we can find the optimal value on the model. We choose samples through an acquisition function that balances exploration (reducing variance of the model) with exploitation (choosing areas where the model expects the solution to be good).\nThe BO algorithm is\n\nStart with some initial sample measurements\nFit a probabilistic model to the data\nCompute the acquisition function based on the model\nFind x^* that maximizes the acquisition function\nSample f(x^*) and add to your data\nIf time/resources are remaining, go to step 2\n\nSections 3 and 4 will cover Gaussian Processes and why we use them as our choice of model.","date":"2025-09-14T00:00:00.000Z"},"blog/Intro-to-Bayesian-Optimization-3.-Intro-to-Bayesian-Statistics":{"slug":"blog/Intro-to-Bayesian-Optimization-3.-Intro-to-Bayesian-Statistics","filePath":"blog/Intro to Bayesian Optimization 3. Intro to Bayesian Statistics.md","title":"Intro to Bayesian Optimization 3. Intro to Bayesian Statistics","links":["blog/Intro-to-Bayesian-Optimization-1.-Optimization-Intuitions","blog/Intro-to-Bayesian-Optimization-2.-The-Bayesian-Optimization-Framework","blog/Intro-to-Bayesian-Optimization-4.-Gaussian-Processes"],"tags":["math"],"content":"This is the third part in my Intro to Bayesian Optimization\n\nOptimization Intuitions\nThe Bayesian Optimization Framework\nIntro to Bayesian Statistics\nGaussian Processes\n\nA question you might have at this point is: this seems like a general framework I could implement with any model; what about it is Bayesian?\nIn this section we’re going to cover the fundamentals of Bayesian Statistics, and why it’s the appropriate choice for the model in the framework described above. We will compare Ordinary Least Squares linear regression with Bayesian linear regression to compare the difference in approaches and to lay the foundation for understanding Gaussian Processes\nAn intro to Bayesian stats will usually start with poking at problems with our normal approach to statistics.\nThe philosophical answer\nIn computing our acquisition function we used \\sigma(x), the standard deviation of our model of the function. Really it’s \\sigma(f(x)). This implies that our model comes from a distribution. But by construction, the function is fixed. Treating it as random was very useful for us, but what’s our justification for doing this?\nTreating functions and parameters as fixed so we can estimate them is called the Frequentist approach. Most statistics you would have done (e.g. linear regression) would have been Frequentist statistics. Treating functions/parameters as coming from probability distributions is the fundamental and differentiating idea in Bayesian statistics.\nFrequentist statistics and confidence intervals\nYou may ask, do we really need to do this? Couldn’t we use a frequentist model and construct confidence intervals in a similar way and use that in our acquisition function?\nWell, you could, but this would be a misuse of confidence intervals.\nConsider a Frequentist (normal statistics) model like linear regression. We have some data \\mathbf{y} and a model described by some parameters \\beta. In model fitting and hypothesis testing, we consider the probability of the data appearing given the choice of parameters.\n\\begin{equation*}\np(\\mathbf{y}|\\beta)\n\\end{equation*}\nWe call this the likelihood. For this purpose, we always consider the parameters \\beta as fixed: there is one true set of parameters and we’re trying to estimate them as best as we can. Our fit \\beta^* is reflective of the best guess, the parameters that maximize the likelihood. There is no distribution for the parameters, so our model isn’t reflective of a distribution itself.\n\\begin{equation*}\n\\beta^* = \\arg\\max_{\\beta} p(\\mathbf{y}|\\beta)\n\\end{equation*}\nThis estimate defines the most likely distribution for the data with the choice of model, there is no distribution for what the parameters or model could be. There’s just one best guess for the objective truth.\nWe do have a notion of uncertainty of our guess, the confidence interval. While they are measures of uncertainty, a confidence interval is not a probabilistic statement about the location of a parameter or function. they are probabilistic statements about the location of the intervals themselves.\nwrong interpretation: there is a 95% probability that the true parameter lies within the 95% confidence interval.\nWhy? If the parameter is fixed and given an interval, then it’s either in the interval or it’s not. 100% or 0%.\ncorrect interpretation: if we were to theoretically repeat this experiment many times, and given the observed data, 95% of confidence intervals we calculate would contain the true parameter and 5% would not.\nThis may seem a bit semantic, so let’s use an example.\nConstructing a confidence interval: ring toss\nLet’s say we’re playing a game with a peg in the ground, and rings that are all of a standard size. We stand behind a line 5m away from the peg and try to get the rings over it.\nI’m pretty good at this game, and throwing 1000 rings I am able to get the ring on the peg 950 times. Let’s say I’ve got a 95% probability of success here.\nNow you close your eyes, I throw one ring, then I remove the peg, and you open your eyes. You want to guess where the peg was. The region that the ring covers is a 95% confidence interval for the location of the peg.\nIf you were to say that the peg was located in the ring, then supposing we repeat this experiment many times, 95% of the time you’d be right, and 5% of the time you’d be wrong. But we only get to look at one example. You wouldn’t say there’s a 95% chance the peg was located in the ring, I either got it or I didn’t, so we use “I’m 95% confident the peg was located in the ring”. But we need this idea of hypothetical repeated experiments to say that.\nWhen we are constructing confidence intervals, we are inferring where pegs are from the ring tosses that are our observed data. They provide us with statements that give us an idea about uncertainty in our estimate, but they do not give us probabilities for the location of the parameters.\nSo we shouldn’t use confidence intervals to measure variance of our estimates, but what about when we do want a probabilistic interpretation of the parameters?\nThe Bayesian approach\nIf we want probabilistic statements of our parameters… then they need to have probabilities. Bayesian statistics is at its heart about full probability models. We don’t necessarily make best guesses, we try to describe distributions of outcomes.\nAgain, consider some data \\mathbf{y} and a model characterized by parameters \\beta. We define a full probability model\n\\begin{equation*}\np(\\mathbf{y}, \\beta)\n\\end{equation*}\nwhich implies a range of other marginal and conditional distributions\n\\begin{equation*}\np(\\mathbf{y}), p(\\beta), p(\\mathbf{y}|\\beta), p(\\beta|\\mathbf{y})\n\\end{equation*}\nwhich we can combine using Bayes’ Rule to get an expression for the distribution of the parameters given the observed data:\n\\begin{equation*}\np(\\beta|\\mathbf{y}) = \\frac{p(\\mathbf{y}|\\beta)\\cdot p(\\beta)}{p(\\mathbf{y})}\n\\end{equation*}\nHowever now we’ve got a bit of a paradox. Consider our models above in the implementation of Bayesian Optimization. The true function was fixed because I defined it that way, but now we’re saying it comes from some probability. To resolve this, we switch our perspective. It’s impossible to ascertain the true state of the world, rather we are modelling our own beliefs, and improving those beliefs as we go. Bayesian Statistics has always come with a lot of philosophical baggage for this reason. The Frequentist approach is to say that the truth exists, and if we pick unbiased estimators then as we get more and more data we can ascertain the truth. The Bayesian approach is to say it doesn’t matter whether the truth exists or not, what matters is our own set of beliefs, and how they can best be informed to describe the data we already have. The interpretation we normally use is:\n\\begin{equation*}\n\\underbrace{p(\\beta|\\mathbf{y})}_{\\text{updated beliefs}} = \\frac{\\overbrace{p(\\mathbf{y}|\\beta)}^{\\text{observed data}}\\cdot \\overbrace{p(\\beta)}^{\\text{old beliefs}}}{\\underbrace{p(\\mathbf{y})}_{\\text{some constant}}}\n\\end{equation*}\neach distribution comes with a technical name:\n\\begin{equation*}\n\\underbrace{p(\\beta|\\mathbf{y})}_{\\text{posterior}} = \\frac{\\overbrace{p(\\mathbf{y}|\\beta)}^{\\text{likelihood}}\\cdot \\overbrace{p(\\beta)}^{\\text{prior}}}{\\underbrace{p(\\mathbf{y})}_{\\text{marginal}}}\n\\end{equation*}\nNote that while everything else can be calculated, we must pick the prior distribution ourselves to start this process. This is why Bayesian statistics is in a sense “subjective”, we get to choose our beliefs going into the problem.\nA way to interpret this approach is to think of the prior as the domain that you think the true parameters could possibly live in, the update process as shrinking that domain to the posterior. Careful choice must be made to make sure that the true parameters lie inside the prior domain, but that it is not too large as to not allow for reasonable inference.\n\nNow consider that \\beta is actually a function of our explanatory variable \\mathbf{x}. Then we can model functions f(\\mathbf{x}) probabilistically with the posterior p(f(\\mathbf{x})|\\mathbf{y}), which is exactly what we’re doing above in our optimization plots.\nWe can construct 95% probability intervals based on the posterior. In the Bayesian framework, we call these credible intervals, and they are probabilistic descriptions for the position of the parameters.\nAs an aside, a full probability model allows us to calculate many other distributions. For instance, if we have observations \\mathbf{y}, and we want to predict new data \\mathbf{y}_{new}, we can fully describe the probability of any model prediction. We call this the posterior predictive distribution\n\\begin{equation*}\np(\\mathbf{y}_{new}|\\mathbf{y}) = \\int p(\\mathbf{y}_{new}, \\beta|\\mathbf{y})d\\beta = \\int p(\\mathbf{y}_{new}|\\beta, \\mathbf{y})p(\\beta|\\mathbf{y})d\\beta = \\int \\overbrace{p(\\mathbf{y}_{new}|\\beta)}^{\\text{likelihood of new data}}\\cdot \\overbrace{p(\\beta|\\mathbf{y})}^{{\\text{posterior}}}d\\beta\n\\end{equation*}\nwhich we can find analytically or through sampling methods.\nThe practical answer\nFrequentist statistics relies heavily on asymptotic theory for results to hold, with measurements of uncertainty based on hypothesized repeated sampling. This means good estimates can require a lot of data. Bayesian statistics can be a much better approach for smaller data sets where we don’t have this reliance, and we are more reliant on describing the data that we already have.\nExample: the Linear Regression\nWe have a model with likelihood\n\\begin{equation*}\n\\mathbf{y} \\sim \\mathcal{N}(\\mathbf{X}\\beta, \\sigma^2 I)\n\\end{equation*}\nFor one explanatory variable, this is simply y_i = \\beta_0 + \\beta_1 \\cdot x_i + \\varepsilon_i where \\varepsilon_i \\sim \\mathcal{N}(0,\\sigma^2)\nHere’s our data. I have constructed it as y_i = \\beta_0 + \\beta_1 \\cdot x_i + \\varepsilon_i, where \\beta_0 and \\beta_1 are unknown:\n\nThe good old fashioned frequentist linear model\nTo fit this model, we want the best point estimate. These are the values of the model that have a line of best fit:\n\\begin{equation*}\n\\beta^* = \\arg\\max_{\\beta} p(\\mathbf{y}|\\beta) = \\arg\\min_{\\beta} \\sum_{i=1}^n (y_i - (\\beta_0 + \\beta_1 \\cdot x_i))^2 = \\left(\\mathbf{X}^T\\mathbf{X}\\right)^{-1}\\mathbf{X}^T\\mathbf{y}\n\\end{equation*}\n\nThe green dotted line is the true line that I generated the data points from (with some noise). Red is the line of best fit.\nThe basic principle of frequentist statistics is that the red line will approach the green line as you collect more and more data. However, with finite samples your fit will always be wrong. You only have a true fit in the limit of collecting data.\nThe Bayesian linear model\nRemember, in Bayesian Statistics we are not trying to find a best fit, we are trying to find a distribution that characterizes the model given the observations of the data. What does this mean?\nWe have the same model, but this time let’s put a prior distribution on \\beta. Lets assume \\beta_0 and \\beta_1 come from a normal distribution. If we’ve picked both our likelihood and priors to be Gaussian, that means the posterior will be Gaussian, and also have a closed form.\nNote: the actual calculations aren’t important here. The point is to describe the Bayesian process\n\\begin{equation*}\n\\text{if}\\quad \\overbrace{p(\\mathbf{y}|\\beta) \\sim \\mathcal{N}(\\mathbf{X}\\beta,\\sigma^2 I)}^\\text{linear regression model}\\quad\\text{and}\\quad \\overbrace{p(\\beta)\\sim\\mathcal{N}(\\mu_0, \\Sigma_0)}^\\text{our prior choice of the parameters}\n\\end{equation*}\n\\begin{equation*}\n\\text{then}\\quad \\underbrace{p(\\beta|\\mathbf{y}) = \\frac{p(\\mathbf{y}|\\beta)\\cdot p(\\beta)}{p(\\mathbf{y})} \\sim \\mathcal{N}(\\mu_n, \\Sigma_n)}_\\text{updated belief of the parameters in the presence of the data}\n\\end{equation*}\n\\begin{equation*}\n\\text{where}\\quad \\Sigma_n = \\sigma^2(\\sigma^2\\Sigma_0^{-1} + \\mathbf{X}^T\\mathbf{X})^{-1}\\quad\\text{and}\\quad \\mu_n = \\Sigma_n\\Sigma_0^{-1}\\mu_0 + \\frac{1}{\\sigma^2}\\Sigma_n\\mathbf{X}^T\\mathbf{y}\n\\end{equation*}\nand so we have our distribution for the parameters \\mathcal{N}(\\mu_n, \\Sigma_n) that we can sample from. (This is a bit of a simplification as we assume a known \\sigma). In practice, there is often no analytical form depending on the choice of prior, but we can still utilize various methods (e.g. Markov Chain Monte Carlo methods) to sample, and then approximate the distribution.\nBut let’s plot some of these samples to see this interpretation.\nSampling the prior\nWe can start by saying our \\beta_0 and \\beta_1 parameters come from a joint standard normal distribution.\nWhat would samples from this prior look like?\n\nWe can try visualizing the prior by sampling many times\n\nSampling the posterior\nOk now let’s update our beliefs by calculating the posterior using the formula from above\n\nHere, each line is a sample of the Bayesian model. The parameters are estimated by a posterior distribution, they are not fixed. Note that each line is a function, and each line is given from a pair of parameters sampled from the posterior. A point drawn from the posterior corresponds to one function, so we say the space of parameters is our function space.\nWe can keep on sampling from the function space and get a visual intuition for the distribution of the mean of the model. This is going to be relevant for us as the mean is a function of the explanatory variable. Note how the distribution is tighter closer to the data points. This reflects how we have more information in this region.\n\nWe say that each function here is credible, it’s a believable result given our beliefs and observed data. There’s no “best” one, they each are samples from the distribution, with different probability densities associated with each line. If were to take the inner 95% of values at each point x, we would be constructing a 95% credible interval. We use credible interval instead of confidence interval to refer to the fact that the region does represent a probability of the function/parameter.\nSection 3 Recap\nIn this section, we justified the use of a Bayesian model which gives its name to Bayesian Optimization: we’re assuming the function comes from a probability distribution as opposed to being fixed, which allows us to reason about the acquisition function probabilistically with a notion of decreasing the variance of our belief in the function. We’ve also justified it with the tendency for Bayesian statistics to be a good choice when you have less data, as Frequentist models rely on asymptotic theory i.e. a lot of data to converge.\nWe used the example of Linear Regression to compare the Frequentist and Bayesian approaches. In the Bayesian approach, we make an assumption about the distribution of the parameters (the prior), then update our beliefs (the posterior) in the presence of the data (the likelihood). The result is a probability distribution that represents our new belief state about the function describing the model.\nHowever, in Bayesian Optimization, we don’t assume to have a linear model. We don’t know anything about the shape of the function, it’s a black box. So we will need to find a Bayesian model that can describe arbitrary functions, not just linear ones.\nThis is the motivation behind Gaussian Processes, which we will look at in the next section.","date":"2025-09-15T00:00:00.000Z"},"blog/Intro-to-Bayesian-Optimization-4.-Gaussian-Processes":{"slug":"blog/Intro-to-Bayesian-Optimization-4.-Gaussian-Processes","filePath":"blog/Intro to Bayesian Optimization 4. Gaussian Processes.md","title":"Intro to Bayesian Optimization 4. Gaussian Processes","links":["blog/Intro-to-Bayesian-Optimization-1.-Optimization-Intuitions","blog/Intro-to-Bayesian-Optimization-2.-The-Bayesian-Optimization-Framework","blog/Intro-to-Bayesian-Optimization-3.-Intro-to-Bayesian-Statistics"],"tags":["math"],"content":"This is the fourth part in my Intro to Bayesian Optimization\n\nOptimization Intuitions\nThe Bayesian Optimization Framework\nIntro to Bayesian Statistics\nGaussian Processes\n\nSo far we have described the Bayesian Optimization framework, and have a basic understanding of Bayesian statistics. In BO, we have no knowledge about the function, so the model we use needs to be able to describe arbitrary continuous functions.\nGaussian Process regression is a nonparametric method to model arbitrary continuous functions given limited data. Sounds perfect for our situation. Most literature and implementations of BO use GPs for this reason. However the usefulness of GPs is wide-ranging, and the study of GPs is a large research area.\nA change of perspective\nLet’s say we have 5 data points. Each with an x and a y value. Let’s ignore the x values for now and just think of our vector of y values:\n\\begin{equation*}\n[y_1, y_2, y_3, y_4, y_5]\n\\end{equation*}\nNow, we could think of it as 5 points in 1-dimensional space, but if we tilt our head, we could also interpret this as 1 point in 5-dimensional space.\nWhat if all the data points in our infinite sample space are just a single point in infinite-dimensional space, With every possible point corresponding to its own dimension?\nThe Gaussian Process\nGaussian Process regressions take this perspective, then define a Gaussian distribution over this infinite-dimensional space, which we call our function space. A point in function space now corresponds to a realization of the data (a function) in our original data space. We pick a Gaussian Process as the prior distribution over the function space.\nThe specific definition is that a Gaussian Process is any (possibly infinite) collection of Random Variables, such that any finite collection of them have a joint Gaussian distribution. So here we define a GP over infinite-dimensional space, and any finite subset (e.g. our data points) is also Gaussian in its joint distribution.\nNote that we are not saying that our y values are gaussian with respect to the x values. We are saying that the y values themselves fall out of a Gaussian distribution with respect to each other. This will become clearer when we visualize the prior.\nKernels\nNow think about what it means for a function to be continuous, it means an arbitrarily small change in our x variables would result in a bounded change in our y variable, i.e. a small x change is a small y change. We can encode this in our new space by saying that if our change in x between two points is small, the correlation in the corresponding dimensions of the function space is large because the y values should be similar. We call this mapping of distance of two points to covariance a kernel k(x, x&#039;) where x and x&#039; are two points.\nA common kernel is the radial basis function (RBF) aka the exponentiated quadratic kernel:\n\\begin{equation*}\nk(x, x&#039;) = e^{-\\frac{1}{2}\\|x-x&#039;\\|^2}\\quad\\text{where }\\|x-x&#039;\\|\\text{ is the euclidean distance between $x$ and $x&#039;$}\n\\end{equation*}\nWhen x and x&#039; are close, k(x, x&#039;) goes to 1, as they go far away, k(x,x&#039;) goes to 0. Note this works for any number of dimensions of explanatory variables. We actually include two hyperparameters into the RBF for tuning, \\sigma_f controls the amplitude and l controls how fast covariance drops off:\n\\begin{equation*}\nk(x,x&#039;; \\sigma_f, l) = \\sigma_f^2e^{-\\frac{1}{2l^2}\\|x-x&#039;\\|^2}\n\\end{equation*}\nThere are many other reasonable choices of kernel you can use depending on what you know about the function you are approximating (e.g. if your function is periodic and you want to encode that). Read more\nSo if we some response variable vector \\mathbf{y} = [y_1, y_2,\\dots, y_n] and some explanatory variables \\mathbf{X} = [x_1^T, x_2^T,\\dots,x_n^T], then our prior distribution for \\mathbf{y} is the Gaussian Process:\n\\begin{equation*}\n\\mathbf{y} = \\begin{bmatrix}f(x_1)\\\\f(x_2)\\\\\\vdots\\\\f(x_n)\\end{bmatrix} \\sim \\mathcal{N}(0, K(\\mathbf{X},\\mathbf{X}))\\quad\\text{ where }\\quad K(\\mathbf{X},\\mathbf{X}) = \\begin{bmatrix}k(x_1,x_1) &amp; k(x_1,x_2) &amp; \\dots &amp; k(x_1,x_n)\\\\k(x_2,x_1) &amp; k(x_2,x_2) &amp; &amp; k(x_2, x_n)\\\\\\vdots &amp; &amp; \\ddots &amp; \\vdots\\\\\\ k(x_n, x_1) &amp; k(x_n,x_2) &amp; \\dots &amp; k(x_n,x_n)\\end{bmatrix}\n\\end{equation*}\nWe may choose the mean not to be 0, but some function \\mu(x) in practice. But knowing nothing else about the function, f(x), a mean of 0 is a reasonable choice.\nSampling the prior\nSo now we have a distribution that describes our function space. Remember, our reasoning here was to find a pretty general way to model arbitrary continuous functions. If we were going to sample a point, what would the function look like?\n\nThe Gaussian part of Gaussian Processes refers to these wiggly curves. Note they are not shaped as Gaussians; we are not saying that the function has a Gaussian shape, we are saying that the points of the function are a priori one sample from an infinite-dimensional Gaussian distribution with a covariance described by the kernel. Some wiggly curves are more likely than others, note how all of these ones centre around 0, that is because of our choice of mean of the GP. The probability of the curves is Gaussian, and that’s what gives them their arbitrary continuous (wiggly) shape.\nConsider the earlier example of Bayesian linear regression. That was in a sense Gaussian too, as we said our two parameters came from a joint normal distribution. Same thing here, except instead of parameters, we consider all infinitely many points on the real number line.\nVisualizing the prior\nWe can take the limit of the number of samples and overlay them to visualize the probability distribution of the prior at each point x.\n\nPosterior\nWe start with a very useful theorem. If we have a Gaussian Process, then by definition the joint distribution of any two subsets of the GP are also Gaussian. And it turns out the conditional distribution of Gaussians is also Gaussian.\nSpecifically, if you consider two subsets of random variables of a Gaussian Process, \\mathbf{y}_1 and \\mathbf{y}_2\n\\begin{equation*}\n\\begin{bmatrix}\n\\mathbf{y}_1 \\\\ \\mathbf{y}_2\n\\end{bmatrix} \\sim \\mathcal{N}\\left( \\left[\\begin{array}{c}\n\\mu_1 \\\\ \\hline \\mu_2\n\\end{array}\\right], \\left[\\begin{array}{c|c}\n\\Sigma_{11} &amp; \\Sigma_{12} \\\\ \\hline \\Sigma_{21} &amp; \\Sigma_{22}\n\\end{array}\\right]\\right)\n\\end{equation*}\nthen\n\\begin{equation*}\np(\\mathbf{y}_2|\\mathbf{y}_1) = \\mathcal{N}\\left(\\mu_{2|1}, \\Sigma_{2|1}\\right)\n\\end{equation*}\nwhere\n\\begin{equation*}\n\\mu_{2|1} = \\mu_2 + \\Sigma_{21}\\Sigma_{11}^{-1}(\\mathbf{y}_1 - \\mu_1)\\qquad\\text{and}\\qquad \\Sigma_{2|1} = \\Sigma_{22} - \\Sigma_{21}\\Sigma_{11}^{-1}\\Sigma_{12}\n\\end{equation*}\nSo if we have observed data \\mathbf{y}_{data}, \\mathbf{X}_{data}, and want to calculate the posterior for prediction points \\mathbf{y}_*, \\mathbf{X}_*, we have prior:\n\\begin{equation*}\n\\begin{bmatrix}\n\\mathbf{y}_{data} \\\\ \\mathbf{y}_*\n\\end{bmatrix} \\sim \\mathcal{N}\\left( \\left[\\begin{array}{c}\n\\mathbf{0} \\\\ \\hline \\mathbf{0}\n\\end{array}\\right], \\left[\\begin{array}{c|c}\nK &amp; K_* \\\\ \\hline K_*^T &amp; K_{**}\n\\end{array}\\right]\\right)\n\\end{equation*}\nwhere\n\\begin{equation*}\nK=K(\\mathbf{X}_{data},\\mathbf{X}_{data}),\\ K_*=K(\\mathbf{X}_{data},\\mathbf{X}_*),\\ K_{**}=K(\\mathbf{X}_*,\\mathbf{X}_*)\n\\end{equation*}\nthen we have the posterior:\n\\begin{equation*}\np(\\mathbf{y}_*|\\mathbf{y}_{data}) = \\mathcal{N}\\left(K_*^TK^{-1}\\mathbf{y}_{data},\\ K_{**} - K_*^TK^{-1}K_*\\right)\n\\end{equation*}\nNote that \\mathbf{y}_* doesn’t need to come from a small or even finite set, it can be the entire infinite-dimensional space which is equivalent to every point on the number line.\nSampling the posterior\nSampling a few times\n\nSampling many times\n\nAs we have a closed form solution for the posterior (one of the nice things about GPs), we can visualize it without sampling. Just specify your level of credibility.\n\nNoisy observations\nSay instead we have y = f(x) + \\varepsilon, where measurements have error\n\\begin{equation*}\n\\varepsilon \\sim \\mathcal{N}(0,\\sigma_m^2)\n\\end{equation*}\nThen the prior covariance matrix of the data points is\n\\begin{equation*}\nK = K(\\mathbf{X}_{data}, \\mathbf{X}_{data}) + \\sigma_m^2I\n\\end{equation*}\nand we can just replace this in the earlier process.\nNote that this gives the posterior distribution, i.e. the distribution for the noiseless function, not the predictive distribution for future measurements which will need to have noise added.\n\\begin{equation*}\np\\left(f\\left(\\mathbf{X_*}\\right)|\\mathbf{y}_{data}\\right)\n\\end{equation*}\nIn the noiseless case, we called p\\left(\\mathbf{y}_*|\\mathbf{y}_{data}\\right) the posterior, but that was just because of the special case where y=f(x)\n\nPrior on the functions? Where are the parameters?\nIn the linear regression case, we defined a prior of the parameters, not the functions that they create. Here, we set the prior on the functions directly:\n\\begin{equation*}\np(f(x)|y) = \\frac{p(y|f(x))\\cdot p(f(x))}{p(y)}\n\\end{equation*}\nThat is because Gaussian Process regression is a nonparametric method. This is a catch-all term for any model that doesn’t use specified models with parameters that can be optimized — including histograms, decision trees, and some support vector machines. However, often when we use this term, what we are actually considering is infinitely many parameters.\nWith a GP, the complexity of the model (i.e. its number of dimensions) increases with the number of data points. Contrast this with linear regression where complexity increases with the number of explanatory variables. Scaling complexity with the number of data points has a huge advantage in low data models. Consider a linear regression, where our fit can be characterized just by the coefficients. No matter how many data points we have, in a one-dimensional case, we can compress the information of the model down into an intercept and coefficient term. However, with GPs, we are never compressing/losing information, in a sense, we are maximally leveraging the data we have available.\nThe flip side of this is that GPs are computationally constrained to low data regimes. We have won statistical efficiency at the expense of computational efficiency. Practically speaking, we must calculate the inversion of the Kernel matrix of the observed data K^{-1}, which is an expensive O(n^3) operation where n is the number of data points. Compare this with a linear regression where we must calculate (\\mathbf{X}^T\\mathbf{X})^{-1} which is an O(p^3) operation, where p is the number of parameters. With GPs we are constrained to working at about 10,000 data points given modern tooling. However, this is fine for Bayesian Optimization where we don’t have so many data points. Also, we do not require this model to be computationally performant, as most time should be spent in function evaluation, i.e. performing experiments. It’s ok for modelling to take a few minutes if the time between experiments is a few hours.\nHyperparameter selection\nWe have introduced 3 hyperparameters. The kernel has terms l and \\sigma_f, and with noise we introduced \\sigma_m. A common method used to pick these is to maximize the marginal likelihood \\arg\\max_{l,\\sigma_f,\\sigma_m} p(\\mathbf{y}|\\mathbf{X},l,\\sigma_f,\\sigma_m) which can be done through gradient methods.\nHowever, there are arguments to be made in the context of Bayesian Optimization that we don’t want to find optimal model hyperparameters, as we may want to err on the side of overestimating the kernel variance so we don’t get stuck in local minima through the iterative process.\nSummary\nWe want to find the combination of x values that gives us an optimal y value, where y = f(x) + \\varepsilon. f is a black box we can sample, but we cannot sample its derivatives. Sampling is expensive so we want to minimize the number of samples we take.\nThe approach we take is to create a probabilistic (Bayesian) model of the function with the data we have, then find the right balance of exploration and exploitation to pick the next point to sample (maximizing the acquisition function).\nWe use a Gaussian Process for this probabilistic model, because it can model arbitrary continuous functions, and is powerful in low data regimes.\n\nStart with some initial sample measurements\nFit a Gaussian Process to the data\nCompute the acquisition function based on the GP\nFind x^* that maximizes the acquisition function\nSample f(x^*) and add to your data\nIf time/resources are remaining, go to step 2\n","date":"2025-09-16T00:00:00.000Z"},"blog/Itsi’s-guide-to-environment-hygeine-with-conda":{"slug":"blog/Itsi’s-guide-to-environment-hygeine-with-conda","filePath":"blog/Itsi’s guide to environment hygeine with conda.md","title":"Itsi’s guide to environment hygeine with conda","links":[],"tags":[],"content":"You fool, you’ve run into more package installation problems while using conda. Are they not installing for weird reasons you can’t understand? Is the little solving wheel spinning forever?\nI’m going to bet that you’re installing everything into your base environment.\nFret not, we can fix it. But it’s time to get environment hygeinic.\nKey ideas\n\n\nYou should be using a different environment for each project that requires different packages\n\n\nYou should keep your base environment as clean as possible, do not install packages into it\n\n\nWhat the heck are environments?\nEnvironments are just collections of packages. Different projects require different packages. Packages are dependent on 100s of other packages. When conda is “solving” it is trying to work out which version of all theses packages are required to get everything working together. This problem gets exponentially harder with the more packages you try to get working together, so if you try to work all projects out of one environment you’re going to get different packages colliding into each other and eventually things will not work.\nWhat should I actually do?\n\n\nBite the bullet and uninstall Anaconda/conda. Guide can be found here, where you want to follow Full Uninstall AND Simple remove: docs.anaconda.com/anaconda/install/uninstall/\n\n\nInstall miniconda. It’s like anaconda but a bare-bones version so you can just install what you need as you go. M1 versions are available: docs.conda.io/en/latest/miniconda.html\n\n\nSet conda-forge as one of your default channels (where you download stuff from): conda-forge.org/docs/user/introduction.html\n\n\nOnce you are in your base environment, install the following three packages:\nconda install jupyter nb_conda mamba\n\n\nNEVER INSTALL ANYTHING ELSE INTO BASE EVER AGAIN (jupyter extensions e.g. jupyter_contrib_nbextensions are allowed)\n\n\nNEVER USE conda AGAIN. NOW YOU ARE A mamba USER. Wherever you would’ve used conda you just sub mamba in now for everything.\n\n\nFor each new project, start a new environment like this:\nmamba create -n env_name_here ipykernel\n(the ipykernel bit will allow you to select this environment when opening jupyter from your base)\n\n\nopen your environments by doing mamba activate env_name, this is where you install your packages for your project (you may need to follow some instructions to get mamba activate env_name working the first time)\n\n\nopen jupyter from base, you will have an option in jupyter now to pick between your environment kernels (this is what nb_conda in your base and ipykernel in your environments allow you to do)\n\n\nWhat the heck is mamba\nmamba is a re-implementation of conda in C++ instead of python. It is much faster, downloads things in parallel, and provides more details when dependency issues arise. You also get a cool snake on your screen every time you use it and everyone comes past your desk and goes “cool what’s that”","date":"2022-09-09T00:00:00.000Z"},"blog/Machine-learning-approach-for-Bitcoin-network-inference":{"slug":"blog/Machine-learning-approach-for-Bitcoin-network-inference","filePath":"blog/Machine learning approach for Bitcoin network inference.md","title":"Machine learning approach for Bitcoin network inference","links":["blog/A-look-at-the-Bitcoin-P2P-network-topology","posts/bitcoinsimulator"],"tags":["math"],"content":"In an earlier post: A look at the Bitcoin P2P network topology, we looked at previous attempts of finding the Bitcoin P2P network topology. As a quick refresh: we have a system where computers talk directly to around 8-12 other computers each on a network about 10,000 computers big. Finding the topology means finding exactly which computers are connected to which others.\nThe central approach to this problem has been in measuring the transactions that are sent around the network. Transactions originate at one computer and then each tells all its peers until the transaction has covered the whole network to be added to ledgers. This is known as a “gossip protocol” because we can think of it like rumours spreading around a town. This mechanism should be viewed as a stochastic process, with the transaction passing along the edges of the network in a probabilistic manner. Randomness is included in a few places.\n\nThe latency between two peers on the network;\nThe processing time on a computer to receive and verify the transactions. This may take longer if there are other processes (or even other transactions) going on simultaneously;\nRandom delay times in sending transactions onto peers that are purposefully built into the Bitcoin protocol. This is known as “trickling” and is discussed in this paper.\n\nSome methods developed to find the topology have attempted to model all of these factors, which requires strong assumptions about the network. The problem we have here is that we have a structural problem where all inferences are highly correlated, and so any assumptions we introduce should be heavily scrutinised. What I found annoying during my research of this problem is that I hadn’t encountered any machine learning approaches. I would have thought that some ML based nonparametric method would be ideal here because it’s quite complex and hard to model. In fact, networks have been studied heavily in the ML literature, but usually in the context of predicting links where others already exist, rather than finding a whole network.\nIf we want to develop an approach, we need some notion of a testing set and validation set. Ideally we’d have a large set of different implementations of the Bitcoin network, but unfortunately we only have the one. So what we’re going to do is inject new nodes into the system, and try to learn some properties of the nodes that would lead to links being formed.\nDelay correlation\nHere’s the idea. If two nodes are peers (there’s a link between them), then they should receive a transaction at a similar time. That’s because one will send it to the other, or they’ll receive it at similar times from other peers with not enough time to send it to each other. If two nodes aren’t peers, then they might for whatever reason still receive a transaction at similar times, but it’s quite unlikely that this will happen many times over multiple transactions. So the idea here is that we should formalise some notion of reception time, then for any two nodes, if those reception times are highly correlated then it’s likely that they’re peers.\nSo let’s imagine we have some transaction k that’s spreading over the network, and we have a monitor node that we connect to every node on the network to receive the transaction. One node is going to be the first that will send us the transaction. We’ll label that time as tr_{k0}. Then for every node we label the time we receive the transaction from them, i.e. we receive the transaction from node i at time tr_{ki}. Note that this isn’t the time that the node receives the transaction, but a fuzzy measurement of that because we have to wait a random time for the node to send it to the monitor. We then “normalise” these times by subtracting the first time we saw. For node i, our delay measurement is t_{ki} = tr_{ki} - tr_{k0}. So if we watch n transactions, at a node i we have the m measurements t_{i1},\\dots,t_{im}. We will treat these measurements as independent outcomes of a random variable X_i that models these delays. This is a nonparametric method so we don’t put any assumptions on X_i.\nNow all we have to do is measure the correlation of all these random variables. We can measure the empirical correlation r_{ij} of X_i and X_j using our delay measurements for i and j. This will give us the delay correlation of those two nodes, essentially a numerical value between -1 and 1 for the link between them. From there, we can classify those links as either existing or not existing. We then use accuracy metrics — specifically recall (true positives/actual positives), precision (true positives/predicted positives) and F1 score (harmonic mean of recall and precision) — to evaluate our methods.\nWe’ll fire up the Bitcoin simulator we developed to generate those delay measurements, then see if we can reconstruct the original network using some algorithms. Let’s consider 500 nodes and 10,000 transactions that we’re going to measure. Given about 3.5 new transactions per second on the real Bitcoin network, this roughly corresponds to 45 minutes of measurement.\nEdge recovery algorithms\nHere’s the three algorithms we’re going to develop and try using. The code can be found here.\nMaxCorr\nSo this one is pretty simple. Let’s consider some node i. If we have n nodes, then we’ll have n-1 possible edges with node i. Let’s take the highest value empirical correlation, say r_{ij}, and infer that i and j are peers. Repeat this for each node. This will produce at most n edge predictions.\nThreshCorr\nIf we have n nodes then we have {n\\choose 2} possible edges to choose from. What we’re going to do here is use some learning. We set up 5 testing nodes and 5 validation nodes. We use F1 score as our metric that we want to optimise. What we want to find is the threshold for the minimum correlation that we will accept if an edge is going to be included in our model. We adjust this threshold to optimise for F1 score on the testing set, then we can evaluate this model as the F1 score on the validation set.\nEdgeCorr\nSimilarly to before, we are looking for an optimal threshold value on the training set. However this time we assign an individual threshold to each node for an edge to be included, then optimise all n of those values. This will give an enormous search space as there are n^n possible combination of values to consider. Optimisation heuristics will need to be used here; I went with simulated annealing.\nResults\nIn one trial, MaxCorr got recall of 11.9% with a precision of 100%. It doesn’t capture many edges but for the ones that it does predict, it gets them right.\nThreshCorr got recall of 23.8% with precision of 76.9%, corresponding to an F1 score of 0.36.\nEdgeCorr had a recall of 54.8% with a precision of 85.7%, making an F1 score of 0.6, better than some of the results in the literature.\nI am fairly happy with this first rudimentary attempt. Further work can be done on improving these algorithms and exploring metrics other than just correlation.","date":"2019-12-19T00:00:00.000Z"},"blog/Maths-and-the-Logistics-of-Vehicle-Routing":{"slug":"blog/Maths-and-the-Logistics-of-Vehicle-Routing","filePath":"blog/Maths and the Logistics of Vehicle Routing.md","title":"Maths and the Logistics of Vehicle Routing","links":[],"tags":["math"],"content":"Here’s an example problem I was working on with some colleagues. Let’s consider a pretty specific setup for a logistical vehicle routing problem. Say we have a bunch of factories located around a city, and each has finished working on some components that we want to bring together at a main warehouse. We want to find the most efficient way to get those components to the warehouse but to complicate things we also have a limited fleet of trucks that are spread out around the factories. We have fewer trucks than we have factories, so some factories will have to rely on their components being picked up by trucks coming from others. For this problem we’ll look at the case that each factory only has one or two components, each of fairly uniform size; but this is all fairly easily generalisable to when this isn’t the case. Also, we only consider the case where the truck fleet has enough capacity to carry all of the components without requiring multiple trips.\nFull Mathematical Model\nThe first thing we’ll do is try to fully describe this problem in mathematical terms. Applied mathematics is really about trying to capture and model the real world so we can use the powerful techniques developed in pure mathematics. Experienced users of applied mathematics will be jumping to model this with integer linear programming. This means it’s an optimisation problem with integers involved where the constraints defining the problem are linear expressions; while that might not seem intuitive immediately we’ll be able to see why that is soon.\nDefining the resources\nThe first step is to define what we know about our setup. Let’s say T is our set of m trucks, F is our set of n factories, w is the warehouse. For convenience, we define the locations L = F\\cup w, the set of factories and the warehouse. We also know the cost of travelling between two places c. The cost can be the distance between two places, the time taken to travel, the monetary cost associated with that leg, or any other cost we want to define. For instance, c_{f,w} is the cost of a truck going from factory f straight to the warehouse. We know the number of components at a factory f, which we’ll call p_f. We have the number of components that truck t can carry, which we’ll call q_t. We also know which factories our trucks start at, which we’ll encode in \\lambda. If truck t starts at factory f, we write \\lambda_t=f.\nDecision variables\nOptimisation at its core is about decision making. So if we’re going to define a problem, we want to know exactly how to interpret an answer to make a decision. Really what we want to know is whether we use a certain truck (because the most efficient solution might be to ignore some of the trucks), and the route for each truck. Let’s define them.\n\na_t is 1 if truck t is used and 0 otherwise\nx_{t,i,j} is 1 if truck t travels from point i to point j, and 0 if not. The points to pick from will be the factories and the warehouse. By putting together all the segments that truck t travels along, we can construct its entire route.\n\nWe also need to define some extra variables to keep track of how full the trucks are. While this isn’t really a decision to be made, it’ll come in handy later.\n\nu_{t,i,j} is equal to the number of components that truck t transports from point i to point j.\n\nObjective function\nThis is an optimisation problem, so we need to define what we’re actually going to optimise for. While there are a number of candidates, the simplest (and usually most useful) option is just to say that we want to minimise the total amount of travelling that’s done across all the trucks. That way the best solution won’t use trucks that we won’t need, and we don’t have trucks driving to opposite ends of the city if we don’t need them to. Whether we want to define that travelling as distance travelled, time taken, or fuel used will be up to each project. We could go a step further here and include the cost of manpower and the trucks involved, but that’s simply incorporated into the model here on a project by project basis. Here’s how we write it in mathematical terms: \\min \\sum_{t\\in T}\\sum_{i,j\\in L}c_{i,j}x_{t,i,j}\nWe can read this as for each truck sum up the cost of each leg multiplied by whether the truck travelled that leg (0 or 1). Take the sum of these terms for each truck, then minimise the result. Optionally, we could also model the case where there is a fixed cost for using each truck. Let’s say if we use truck t, there is a fixed cost of b_t. In this case, we would want the leg costs a_t to be measured in the same units, so monetary costs would be best as opposed to distance or time. We would then alter the objective function to\n\\min \\sum_{t\\in T}\\sum_{i,j\\in L}c_{i,j}x_{t,i,j} + \\sum_{t\\in T}b_t a_t\nConstraints\nIn order to convert the real world problem into a mathematical format, it is extremely useful to think of the rules of the problem as geometric constraints to the objective function. In this problem, we will see that all the constraints are linear expressions, which is a highly desirable property of a problem as it makes them easily solvable. So let’s go step by step through the problem, describing what we want to achieve, a more explicit way of describing it, then the mathematical expression.\nFirstly, we define the domains of the variables that we defined before.\n\\begin{align}\n\na_t &amp;\\in \\text{{0,1}} &amp;&amp; \\forall t\\in T \\newline\n\nx_{t,i,j} &amp;\\in \\text{{0,1}} &amp;&amp; \\forall t\\in T,\\ \\forall i,j\\in L \\newline\n\nu_{t,i,j} &amp;\\in \\mathbb{N} &amp;&amp; \\forall t\\in T,\\ \\forall i,j\\in L\n\n\\end{align}\nWe want to ensure that all the components are picked up. The way we do this is by measuring the change in the number of components that trucks are carrying as they pass through the factories. For each factory, the total change of components across all the trucks must sum to the number of components at the factory.\n\\begin{equation}\n\n\\sum_{t\\in T}\\left(\\sum_{j\\in L}u_{t,f,j} - \\sum_{i\\in L}u_{t,i,f}\\right) = p_f,\\qquad \\forall f\\in F\n\n\\end{equation}\nNow we don’t allow a truck to travel from one location to the same location as one leg. That is, for each truck and location, the truck cannot travel from the location to the same location.\n\\begin{equation}\n\nx_{t,i,i} = 0,\\qquad \\forall t\\in T,\\ \\forall i\\in L\n\n\\end{equation}  \nThis next equation will include two pieces of information. A truck can’t transport any components down a leg if it cannot travel down that leg. When x_{t,i,j}=0, then u_{t,i,j}=0. Also, the most components that the truck can take down a leg is the capacity of the truck. When x_{t,i,j}=1, u_{t,i,j}\\le q_t. We combine these as\n\\begin{equation}\n\nu_{t,i,j} \\le q_tx_{t,i,j},\\qquad \\forall t\\in T,\\ \\forall i,j\\in L\n\n\\end{equation}\nWe’ll need a few equations to describe the paths that the trucks are allowed to travel down. We only want trucks to travel out of locations that they travelled into in the first place, so we don’t get trucks appearing or disappearing. For each truck, at each factory except its starting location, the number of times the truck enters the factory is equal to the number of times the truck leaves the factory.\n\\begin{equation}\n\n\\sum_{i\\in F}x_{t,i,f} = \\sum_{j\\in F}x_{t,f,j},\\qquad \\forall t\\in T,\\ \\forall f\\in F,\\ f\\ne \\lambda_t\n\n\\end{equation}\nHowever, we do want trucks to appear at their starting factory if we use them. For each truck, the number of legs travelled out of its starting factory is 1 if we use it or 0 otherwise, so equal to a_t. Similarly, we want each truck arriving at the warehouse once if we use them.\n\\begin{align}\n\n\\sum_{j\\in F}x_{t,\\lambda_t,j} &amp;= a_t, &amp;&amp; \\forall t\\in T \\newline\n\n\\sum_{i\\in F}x_{t,i,w} &amp;= a_t, &amp;&amp; \\forall t\\in T\n\n\\end{align}\nAlso, we don’t want trucks entering their starting factories or leaving the warehouse\n\\begin{align}\n\n\\sum_{i\\in F}x_{t,i,\\lambda_t} &amp;= 0, &amp;&amp; \\forall t\\in T \\newline\n\n\\sum_{j\\in F}x_{t,w,j} &amp;= 0, &amp;&amp; \\forall t\\in T\n\n\\end{align}\nSo to summarise: If we use a truck (a_t=1), then it must appear at factory \\lambda_t, not return to \\lambda_t, and arrive at and not leave the warehouse w. A truck can only enter a factory if and only if it leaves it, and cannot travel from one factory to itself. A truck can only carry goods down a leg if it is travelling down that leg, up to a maximum of its capacity. All components are picked up by a truck, and since all trucks must arrive at the warehouse, all the components arrive as well. Note that all of these equations are linear expressions. That is, variables are only ever added to each other, never multiplied.\nSolving the problem\nThis set of variables, objective function and constraints completely describes the problem. We can now code the problem up using embedded modelling languages such as JuMP in Julia or PuLP in Python. Then we can use solvers such as Gurobi or CPLEX to find the optimal solutions.\nHowever, at this point we run into a problem. It turns out that this takes extremely long times to solve for anything over about 100 components. That’s because there are two coupled problems that we’re trying to solve. It’s both an assignment problem and a routing problem. We want to decide which components get picked up by which trucks, but also what the optimal route is for the trucks to get to the factory. The way the problem is described, these two elements are directly linked to one another, compounding the computation time needed to solve them. Now we could use more advanced decomposition techniques to simplify things, but instead let’s try and decouple things with a heuristic solution.\nHeuristic Model\nWhat we’re going to do here is sacrifice having the best solution that takes to long to find in favour of getting a good solution that we can find quickly. We decouple the problem by splitting it into two stages: assignment and routing. First we decide which trucks are going to pick up which components (in a suboptimal but still good manner), then we find the fastest routes for each truck individually to pick them all up. This is opposed to the full model where we calculate all these things optimally at the same time, so the routing choice affects the assignment choice and vice versa.\nStep 1: Assignment\nWe need a good way to assign components to trucks. One way we can think about this is to reduce some penalty associated with a truck picking up a component. We want larger penalties if the truck has to travel far out of its way, and smaller if the components are directly on the way to the warehouse.\nThe penalty we use I will refer to as the elliptical detour cost. For a truck starting at factory f, the penalty for the truck picking up a component at factory j is\n\\begin{equation*}\nd_E(f,j) = c_{f,j} + c_{j,w} - c_{f,w}\n\\end{equation*}\nThe penalty is the direct path the truck would have to travel to pick up the component and go to the warehouse minus the cost of travelling straight from the factory to the warehouse. Essentially this measures how much extra the truck would have to travel if we only considered that component. If we use distance as our cost function, a constant penalty would describe an ellipse of locations with foci at the factory and the warehouse. A smaller ellipse would correspond to travelling less out of the way on the way to the factory, so that’s what we aim to minimise.\nNow we can fully model this assignment subproblem. The decision variables we will use are\n\n\na_t is 1 if truck t is used and 0 otherwise\n\n\ns_{t,f} is the number of components that truck t picks up from factory f\n\n\nOur new objective function is to minimise the penalty associated with picking up each component.\n\\begin{equation*}\n\\min \\sum_{t\\in T}\\left(b_tc_t + \\sum_{j\\in F}s_{t,j}d_E(\\lambda_t,j)\\right)\n\\end{equation*}\nFor our constraints, we first define the domain of the variables:\n\\begin{align}\n\na_t &amp;\\in \\text{{0,1}} &amp;&amp; \\forall t\\in T \\newline\n\ns_{t,j} &amp;\\in \\mathbb{N} &amp;&amp; \\forall t\\in T,\\ \\forall j\\in F\n\n\\end{align}\nWe require that all the components are picked up.\n\\begin{equation}\n\n\\sum_{t\\in T}s_{t,j}=p_j,\\qquad \\forall j\\in F\n\n\\end{equation}\nWe only use pick components up with a truck if we use a truck, up to a maximum of its capacity.\n\\begin{equation}\n\n\\sum_{j\\in F}s_{t,j}\\le q_ta_t,\\qquad \\forall t\\in T\n\n\\end{equation}\nWe can solve this optimisation problem fairly quickly. Note that we’ve reduced the complexity from O(mn^2) variables and O(mn^2) equations to O(mn) variables and O(mn) equations.\nStep 2: Routing\nNow that we know which truck picks up which components, all we have to do is figure out the best route for each truck to take. Note that this can be worked out independently for each truck. It essentially involves modifying the routing equations in the full mathematical model. This requires m repetitions of a problem with O(n^2) variables and O(n) equations, and is fairly fast to solve.\nAll in all, this heuristic worked fairly well on dummy problems, and allowed us to solve problems with well over 200 factories involved.","date":"2019-11-26T00:00:00.000Z"},"blog/My-Master's-Thesis.-Bitcoin,-Network-Topology,-Machine-Learning":{"slug":"blog/My-Master's-Thesis.-Bitcoin,-Network-Topology,-Machine-Learning","filePath":"blog/My Master's Thesis. Bitcoin, Network Topology, Machine Learning.md","title":"My Master's Thesis. Bitcoin, Network Topology, Machine Learning","links":["zSystem/Assets/thesis.pdf"],"tags":["math"],"content":"I completed my master’s degree in mathematics and statistics at the University of Melbourne under the supervision of Professor Peter Taylor. My research focused on methods that have been used to find the topology of the P2P network underlying Bitcoin, and I developed a novel machine learning approach to solving this problem using edge recovery algorithms based on correlations of the arrival times of transactions between pairs of nodes. Interestingly, knowledge of the network topology allows for the deanonimisation of Bitcoin users.\nRead Here\nThe Bitcoin P2P Network Topology: a Review of Inference Methods and Machine Learning Approach","date":"2019-10-11T00:00:00.000Z"},"blog/On-Good-Vegan-Recipes":{"slug":"blog/On-Good-Vegan-Recipes","filePath":"blog/On Good Vegan Recipes.md","title":"On Good Vegan Recipes","links":[],"tags":["recipes"],"content":"Most vegan recipes that you find are bad. In two ways: the food they try to make is bad, and the recipe layouts are bad.\nThe food being bad is, I think, a result of the content commodification of places like YouTube and Facebook that are usually linked to vegan websites. In order to pump out content, the current wave of popular vegan recipe-makers often go to publish before they’ve spent enough time on it, or even in some cases publishing while they’re only making it for the first time. This has led to the vast majority of recipes available being terrible, and annoying formats such as “what I eat in a day” style videos. For instance, if you were to search for good Seitan recipes, you would find far more results than you could ever process. Usually, one recipe that the writer will say is great. I have not been able to find a resource that in detail explains what different effects recipes have (e.g. altering water content, oil content, non-flour solids, water temperature, cooking time). Maybe that resource exists, but it is too hard to find under the torrent of bad information.\nWhile this affects the entire online food environment, the vegan world is still plagued by the hippy health aesthetic. It’s impossible to tell for a lot of vegan channels whether they’re doing things because they work or because they fit the aesthetic. It also makes things really annoying to use. Sometimes though, good recipes (e.g. this one seitan recipe) do come out but they’re hard to find under the other trash.\nThe rest of the food world has seen a boom in the way good recipes are produced. Test kitchens are becoming ever more popular and the way things are presented is becoming more refined, focussing more on good explanation (see the rise of YouTube chefs like Binging with Babish and Adam Ragusea). However, there has been no such movement in the vegan world. Fortunately, we can still cash in on these improvements. Serious Eats has in the past produced many vegan recipes on an annual basis which it has made available through its resource the vegan experience. Further, that website and others have a focus on technique that can be applied to other areas. For example, America’s Test Kitchen video series on science-led technique that really improves cooking of mushrooms and cauliflower.\nGenerally, until we see more of a shift to this style that is dedicated to vegan cooking, the best you can really do is follow websites and channels such as these and try to learn what you can that will be useful.\nThe second qualm I have with recipes is their terrible physical layout. As much as I love Serious Eats, their recipes are hard to use, even on a phone (you shouldn’t have to scroll away from your step at any point). Including instructions on the ingredients list just makes things confusing. They do this because in developing recipes, usually all prep is done before the actual cooking. In home kitchens, people don’t usually have a ton of tiny bowls hanging around to hold everything and people are more focussed on saving time. This can be optimised easily while developing a recipe. For instance, compare Serious Eats’ channa masala with mine. I’ll tell you to cut the onions when it’s time to cut the onions.","date":"2019-12-16T00:00:00.000Z"},"blog/Optimising-warehouse-distribution-logistics":{"slug":"blog/Optimising-warehouse-distribution-logistics","filePath":"blog/Optimising warehouse distribution logistics.md","title":"Optimising warehouse distribution logistics","links":["Input.xlsx","Data.csv","Packing.csv","Summary.csv"],"tags":["math"],"content":"Lack of knowledge of optimisation techniques can be a large burden, especially in logistics. Companies are often ignorant that they can do better, so miss out on saving time, money and effort. A friend of mine has been working as a logistic manager at a large international distribution centre, and described some of the work he was doing. It turns out that a significant amount of work that the company was doing could be automated with mathematical optimisation.\nFiles\nData for a dummy problem: Input.xlsx\n3 output files: Data.csv --- Packing.csv --- Summary.csv\nThe code developed for this problem can be found here.\nThe problem\nMy friend was working at a distribution centre attached to a factory. The various products made at the factory would have to be tested (each with different testing durations) then shipped out to the various markets around the world. Products are made in various quantities at different times during the month, and there is previous excess product from previous months that can be shipped. Part of my friend’s job was to make sure that the products were getting out in the most efficient way possible using the 25 and 60 m^3 containers available with a 4 week planning horizon. Each market would be allocated the minimal amount of containers determined by the products that were sent to them. E.g. a market that required 140 m^3 would be allocated one 25 m^3 and two 60 m^3 containers. Further, the workers in the warehouse could pack a maximum of 5 containers each day. The scale for our dummy problem is 22 products and 14 markets, with 46 individual orders from those markets (e.g. France orders 50 units of product 3 is an order). All of a given product is not necessarily created in one go.\nReally this boils down simply to the problem: We have products being made at various times that need to be tested then shipped to various international markets in the most efficient way possible.\nIt turns out that the company was getting people to solve this problem manually for every planning cycle, every 4 weeks. Not only would this take hours to do, but it would also not be optimal. It’s also important to note that decisions for the production of products and allocation of containers is done independently, whereas considering them together would allow for much more time and money saving by optimising the entire supply line.\nMathematical model\nIn order to automate this process, we’ll need to model the problem and then solve for the optimal solution. Once we do that, it’s a matter of adding it to the data pipeline so the optimal solution will pop out automatically. This problem very naturally lends itself to modelling it as an ILP (integer linear program) --- the variables are integers, we pick a linear objective function, and the constraints are linear equations and inequalities as we will see.\nThe parameters\nThe first thing we have to do is to define the parameters as set out in the problem. There are all the things we are given to start off with.\n\nP = {products}\nM = {markets}\nT = {1,2,\\dots,28}\nC = {types of containers}\nL = maximum containers that can be sent each day\nd_{ij} = demand of product i\\in P at market j\\in M\ns_{it} = new supply of product i\\in P at day t\\in T\nc_{jk} = number of type k\\in C containers allocated to market j\\in M\na_k = capacity of container k\\in C\nv_i = volume of 1 unit of product i\\in P\n\nThe decision variables\nWe want to calculate the best decision to make, which will take the form as the values of some variables. We want to know when to send containers to each market, and what products that go into those containers.\n\nx_{jtk} = the number of containers of type k\\in C sent to market j\\in M on day t\\in T\nz_{ijt} = the number of units of product i\\in P sent to market j\\in M on day t\\in T\n\nAlthough it is not a decision, it is useful to have a variable that tells us how much stock we have in the warehouse at the end of each day.\n\ny_{it} = the number of units of product i\\in P stored at the end of day t\\in T\n\nThis also lets us include a parameter for any amount of stock that we start off with (left over from previous months).\n\ny_{i0} = the number of units of product i\\in P at the start of the period\n\nThe objective function\nWe need some metric that we’re going to optimise for. Some way to measure what the ‘best’ or ‘most efficient’ solution is. Let’s interpret efficiency by saying that we want stock going out as quickly as possible. The faster we send out stock, the less we’ll have to store in the warehouse, so that’s what we’re going to use as our function.\nWe’ll be able to calculate how much stock we have at the end of each day, and then we can sum that up across all the days to give us an efficiency score. The less we have in total across all the days, the better the solution. In mathematical notation, this is\n\\begin{equation*}\n\\min \\sum_{i\\in P}\\sum_{t\\in T} y_{it}\n\\end{equation*}\nHowever, it may be helpful to not minimise the amount of units of stock we store, but the volume of stock that we store. This is a simple modification.\n\\begin{equation*}\n\\min \\sum_{i\\in P}\\sum_{t\\in T}v_iy_{it}\n\\end{equation*}\nA very similar modification can be made if we want to instead minimise the value of the items stored in the warehouse, if we know the value for each unit of product. It’s up to the warehouse manager to decide which particular function he wants to optimise.\nThe constraints\nHere we transform the rules of the problem into algebraic statements. We think of the rules as geometric boundaries in space that we cannot cross. Once all the boundaries are established, we can find the optimal solution in those boundaries.\nFirstly, we define the domains for each of the variables. We want the number of each type of container sent to a market on a given day (x_{jtk}), the number of units of each product stored at the end of each day (y_{it}), and the number of units of each product shipped to each market on a given day (z_{ijt}) to all be counting numbers. We don’t want them to be negative, and it doesn’t make sense to send half a container.\n\\begin{align}\n\nx_{jtk} &amp;\\in \\mathbb{N} &amp;&amp; \\forall j\\in M,\\ \\forall t\\in T,\\ \\forall k\\in C\\newline\n\ny_{it} &amp;\\in \\mathbb{N} &amp;&amp; \\forall i\\in P,\\ \\forall t\\in T\\newline\n\nz_{ijt} &amp;\\in \\mathbb{N} &amp;&amp; \\forall i\\in P,\\ \\forall j\\in M,\\ \\forall t\\in T\n\n\\end{align}\nWe want to make sure the demand for each product at each market is met by the end of the 4 week period.\n\\begin{equation}\n\n\\sum_{t\\in T}z_{ijt} = d_{ij},\\qquad \\forall i\\in P,\\ \\forall j\\in M\n\n\\end{equation}\nWe want the number of each type of container we allocate to each market to be sent.\n\\begin{equation}\n\n\\sum_{t\\in T}x_{tjk} = c_{jk},\\qquad \\forall j\\in M,\\ \\forall k\\in C\n\n\\end{equation}\nThe most amount of containers that can be sent in a day is the container limit.\n\\begin{equation}\n\n\\sum_{j\\in M}\\sum_{k\\in C}x_{jtk}\\le L,\\qquad \\forall t\\in T\n\n\\end{equation}\nWe don’t want containers being sent on weekends, because we won’t have workers then.\n\\begin{equation}\n\n\\sum_{j\\in M}\\sum_{k\\in C}x_{jtk} = 0,\\qquad \\forall t\\in\\text{{6,7,13,14,20,21,27,28}}\n\n\\end{equation}\nThe amount of items we send to a market on a given day must fit in the containers that we send them.\n\\begin{equation}\n\n\\sum_{i\\in P}v_iz_{ijt}\\le \\sum{k\\in C}a_k x_{jtk},\\qquad \\forall j\\in M,\\ \\forall t\\in T\n\n\\end{equation}\nLastly, the amount of a product we can send on a given day is the total amount stored from the previous day with the addition of any new products that have finished their testing. Any that is not shipped must be stored at the end of that day.\n\\begin{equation}\n\ny_{it} = y_{it-1} + s_{it} - \\sum_{j\\in M}z_{ijt},\\qquad \\forall i\\in P,\\ \\forall t\\in T\n\n\\end{equation}\nSolving the model\nAfter coding this up, non-industrial solvers on a basic computer can solve this problem in under 20 seconds. A huge boost to efficiency, time and money. Keep in mind that the solution found with these solvers is provably optimal. There is no finding a solution better than this based on the model.","date":"2019-12-04T00:00:00.000Z"},"blog/The-Metamorphosis":{"slug":"blog/The-Metamorphosis","filePath":"blog/The Metamorphosis.md","title":"The Metamorphosis","links":[],"tags":["book-review"],"content":"Franz Kafka, 1915, an absurdist? modernist? Novella\nI’m sure tons has been written about this bad boy, but I’m going to take a crack at it before reading any other analyses, then see later if I’m stupid.\nThe Metamorphosis is a story about the inherent conflict and dehumanizing nature of a society that forces people to generate value in order to survive. Oh no, I’m a bug and I’m late for work! It’s not the transformation into a bug that makes Gregor inhuman; it is that he cannot work, and how this infiltrates his thoughts and his family.\nGregor has a very pure nature. There is this kind of pure human condition that he seeks to obtain—supporting his family so that his parents can enjoy leisure and sending his sister Grete to the conservatory to learn violin. He doesn’t like his work; he explains the hated nature of being a traveling salesman in very objective terms, as though we’re meant to think that it’s obvious. He has a desire to eventually tell his boss to go shove it. In his ideal world, everyone is happy, healthy, and content, and not forced to work. His thoughts upon his transformation are just about the anxiety of not being able to work and support his family. As his family’s situation gets worse and worse, he continues to be depressed about their financial situation. There is also an aspect where he worries about his own self-actualization, symbolized by the painting he wants to keep in his room, but this is secondary to his concerns about his family.\nThe lack of ability to do work is the main conflict. Gregor is clearly anxious about this, and the opening is an almost unreal realization of the kind of catastrophized thinking someone might have when their family’s well-being depends on their selling their labor. His manager appears when he’s less than an hour late for work (when he’s never been late before in his life) and comically rapidly goes into a barrage about his lack of work, how his boss thinks he’s stolen money, and that his work is even unsatisfactory. This catastrophization goes even further as he can’t defend himself, only squeak. At no point does he really consider the ramifications of becoming a bug; he only tries to save his job. While there is initial disgust at his metamorphosis, this is all done in the context of his losing income, which ties these concepts together. His family starts out tolerating or loving him, especially his sister. But this breaks down due to the family now having to work and rent their flat. The pressures put on their lives drive at the humanity of the family, as they grow to revile him since he makes it hard for them to survive. Due to his presence, they feel forced to keep the large apartment; the work drives them all to exhaustion; the sister cannot pursue her passions; and he makes it impossible for them to rent the spare room in the apartment. This is a threat to their survival, and as they get more desperate, they get more violent, until the sister, who initially loved him in bug form, completely declares him inhuman and says he should be gotten rid of. This is entirely a result of his not being able to generate value. Interestingly, it is the people in the story who don’t derive value from Gregor that are okay with him. The family and his work despise him, but the cleaning lady and the lodgers who encounter him don’t inherently hate him. You can imagine a world where the family’s survival was not predicated on Gregor’s value, in which the family would have been initially afraid but continued to love and accommodate Gregor.\nI think two ideas are being presented here. Due to the way society is set up, it is dehumanizing to labor for someone else, but you are also forced to because it is even more dehumanizing not to work and become invalid.\nEvery character who sells their labor is somewhat despicable. Gregor is servile and hates his job; there is an errand boy described as spineless, and Gregor despises the maid that comes to the house. The Samsas also rent out a room in their house, and this trade of value for money is also dehumanizing as they give up their space, and the lodgers are condescending and entitled. The trade of value for money projects hierarchies that get in the way of the pure world that Gregor wants.\nAt the same time, it is even worse not to earn money because then you are invalid in the society. Gregor is made figuratively inhuman in this sense. I think the obvious parallel can be drawn to becoming disabled and the ramifications of that under a capitalist society where you are forced to sell labor and cannot. But Kafka points towards other examples like being old, fat, clumsy, or even unsuccessful in business. There is a parallel to the furniture that is sentimental to the family but serves no purpose to the lodgers and just ends up gathering dust in the room. You need to continue to be valid and push through, or else your survival is threatened. And in this society, it is so easy for something to change and to become invalid, and this will destroy your humanity. Gregor is made inhuman; the family is made inhuman. They are all invalid.\nI think it’s interesting how things resolve when Gregor dies. There is a moment of sobriety. The family weep and are sad—they have lost their son and brother. They take control of their space and dignity by throwing the lodgers out. As Gregor is dead, there is no conflict between his humanity and his value generation. Humanity is completely restored to him and the family. They continue to be rude to the cleaning lady because she is still having to participate in the conflict. It turns out the only way out is to die.\nThis is all summed up in the last line. The Samsas are now optimistic, as they were when Gregor first got the job and was able to allow the family to thrive. Grete mirrors Gregor at the start, stretching out her young body as Gregor feebly tried to make use of his new insect one. As opposed to the loss of value generation Gregor experiences at the start, here Grete gains value generating ability as she has suddenly transformed in the parents’ eyes to being beautiful and able to marry. Her humanity is now determined by her beauty. The story is doomed to repeat.\n5⁄5","date":"2024-11-14T00:00:00.000Z"},"contact":{"slug":"contact","filePath":"contact.md","title":"Contact Me","links":[],"tags":[],"content":"I love getting emails.\nYou can find me here: contact (at) itsiweinstock.com\nOther Accounts:\n\nLinkedIn: Your LinkedIn Profile\nGitHub: Your GitHub\n\nPlease get in touch for\n\nMusic: If you’re interested in chamber music\nFood: If you want to get vegan food together\n\nFeel free to reach out about:\n\nCollaboration opportunities\nVegan food recommendations\nAI/ML projects\n\nI try to respond to all messages within a few days. Looking forward to hearing from you!","date":"2025-10-15T17:01:02.505Z"},"index":{"slug":"index","filePath":"index.md","title":"Welcome to my website","links":["blog/My-Master's-Thesis.-Bitcoin,-Network-Topology,-Machine-Learning","resume.pdf","recipes","Couchers.org","bookshelf","movieshelf","tvshelf","tea-notes"],"tags":[],"content":"\nHi, I’m Itsi.\nI am an AI/ML guy from Sydney, Australia and live in San Francisco, USA.\nMy main interests are in how we get to a vegan world, and having a good time.\nThings I work on\nI have worked in the Alt Protein space, running data science at Climax Foods; where I ran our collaboration to reformulate Plant Based Mini Babybel, among other project; and with the Sustainable Protein Action Lab.\nMy current projects are as an AI Engineer at CloudTrucks, leading the implementation of our flagship AI product, along with Couchers.org, a nonprofit I co-founded to replace Couchsurfing, and being the Editor-in-Chief of VILF, a comprehensive vegan companion to San Francisco.\nMy background is in Statistics and Machine Learning. I started my career in Quantitative Research at Akuna Capital, a high-frequency trading firm. I completed my thesis for a master’s degree in mathematics and statistics at the Univeristy of Melbourne under the supervision of Professor Peter Taylor; focusing on developing a new machine learning method for inferring the topology of the Bitcoin P2P network, a task which has a significant impact on the pseudonymity properties of the cryptocurrency.\nDownload my resume.\nOther things\nMusic\nI have played the violin for over 20 years. I play with San Francisco Civic Music, and sometimes the Awesome Orchestra and a string quartet.\nI am very into 20th century classical music. I have taken several courses in music theory and have previously composed pieces for chamber groups. For an intro to 20th century music, check out this playlist.\nFood\nI have eaten a lot. And I have a lot of opinions. I run VILF.org, a definitive vegan guide to SF. And the associated VILF blog.\nI’m a big fan of cooking. I frequently organize home-cooked dinners and outings with my friends. My three favorite vegetables are eggplant, cauliflower and cucumber. Please check out my 🍲 Recipes.\nTravel\nI’ve gone to a whole bunch of places! I like to collect carpets in every country I travel to. Through travel, I discovered couch surfing, which later led me to co-founding Couchers.org.\nCurated Stuff\nMedia\n📖 Books  |  🎬 Movies  |  📺 TV\n\nFood and Drink\n🍃 Tea Reviews  |  🍲 Vegan Recipes\n📰 VILF Blog  |  🌱 Vegan Guide to SF  |  🗽 Vegan Guide to NYC\n\nMusic\nChronological Bangers of the 20th century\n\nSongs that I’m about\n\nParty Bangers\n","date":"2025-10-15T17:01:02.513Z"},"tea-notes":{"slug":"tea-notes","filePath":"🍃 Tea Notes.md","title":"🍃 Tea Notes","links":["blog/How-to-get-into-tea"],"tags":[],"content":"My guide for how to get into tea\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nnamedatere-buy?typecommentsbrew notessourcePremium White Peony (Bai MuDan)2025-10-08NWhiteLittle too mild, but there’s nice flavorteavivreHuo Shan Huang Xiao Cha2025-10-01YYellowRoasty, a little sweet. Like popcorn. Simple and greatteavivreTurtle Dove 20202025-09-26YWhiteYummy, fruity, like sweet peach ice teawhite2teaDark Peony 20242025-09-22YWhiteWhite/Black mix. More on the white end, light and bright. A lil fruity. Could do with more flavor but it’s good.white2teaJonia 20252025-09-17YWhiteYum. Like a mix of white and oolong that’s a little bit bready and milky. Light sweetness. Coolwhite2teaPredawn Dark 20232025-09-15YPuer - RipeVery nice. It’s charcoal roasted but not smokey. Roasty, little molassis, little barn, really thickwhite2teaOrientalism and the Generated Image 20242025-09-14NPuer - RawNothing I like about this. Just grassy and badwhite2teaSilver Fox 20242025-09-12NWhiteNot so interesting but I think I overdid it, needed cooler waterwhite2teaDian Hong Black Tea - Golden Tip2025-09-09YBlackGreat black tea. herby, good acidityteavivreSchedule White 20242025-09-05YWhiteSweet, fruity, herby, a lot going on. Great aftertaste. Serious stuff for the $7 pricewhite2teaNuo Xiang Shu 20032025-09-02YPuer - RipeSuper old and syrupy. Not my faavorite but nice to have around.white2teaAnhua Tianjian 20212025-09-01NHeichaA little funky and interesting, but didn’t love itwhite2teaJade Yellow Tea2025-08-29NYellowVery midNeed to respect it and do it at 85Cguy on messengerSnowflake Dancong2025-08-28NOolongKinda boriingwhite2teaDrills and Jeans 20252025-08-23NWhiteNice, a little too subtle. slightly roasty marshmellow or hot chocolatewhite2teaSmoky Charcoal Ruby Oolong2025-08-21YOolongNot super smoky or charcoaly. A little sour and chocolate notes. Maybe refreshing for a cold brew? Xander likes itdaughter’s teaJin Xuan Milk Oolong2025-08-17NOolongMeant to be a milk oolong but it’s way too subtle. Just an ok oolongteavivreFruity Citrus Ruby Oolong2025-08-16NOolongSmooth, sweet, fruity, but not as delightful as their other stuff. I might get it if I was doing another order from themdaughter’s teaDualist 20242025-08-15NBlackOk but bit boring black teawhite2teaGongmei 20192025-08-10NWhiteVery smooth and soothing, fruity notes wihtout being sweet. But not blown awayAgeless Phase 20242025-08-08NPuer - RipeBoringwhite2teaKarst 20232025-08-07YWhiteFruity, smooth, sweet, floral, delicious. A little on the subtler end but still goodDefinitely could daily drive. Cold brew?white2teaSmokeshou 20212025-08-06YSmokedReally sweet delicious campfire smoke flavor, like smoked salmon, no bitterness or astringency or ashtray.white2teaMoon Bear 20242025-08-05YPuer - RawSmells like white/green/raw, but a rich molassis caramel peanut brittle mixed with roast grain flavor. A little subtle but nice.white2teaEn Passant 20232025-07-27NPuer - RipeJust bitter, not too interestingwhite2teaTheophilus 20242025-07-23NPuer - RipeNot super interestingwhite2teaBig O V3 20232025-07-03NPuer - RipeKinda just boringwhite2teaDitch Pike 20242025-06-22YBlackreally beutiful. sweet, herby, low bitterness, rich. yummaybe get it as daily driverwhite2teaBellwether 20242025-06-20YPuer - Rawgentle, light, full. kinda lovely. Not remarkable for the price but very nicewhite2teaCacao 80 20242025-06-15YPuer - RipeCrazy bitterneeds experimentation. half a coin regular/cold brew. mix with milk/sugar into hot chocolatewhite2teaShotgun Shack 20242025-06-07NPuer - RipeA little boring and just astringentwhite2teaReading Room 20232025-05-30YPuer - RipeSweet, syruppy, refined. A bit expensivewhite2teaInjured Coast 20222025-05-07NPuer - RawA little roasty. Just tastes like astringent black teawhite2teaOrganic Nonpareil Ming Qian Dragon Well 20252025-04-19NGreenchestnut, umami, a little sweetteavivreRectrix 20222025-04-18NBlacka little sweet and delicious, but not enoughwhite2teaSun Fu 20182025-04-06NHeichaKinda moldy funky not so pleasant. Wet log in a not so good waywhite2teaLapsun 20232025-04-05NSmokedA little smoky, a little black, nothing crazywhite2teaLa Sombra 20232025-03-30NPuer - Rawkinda green, boringwhite2teaFloral Honey Ruby Oolong2025-03-28YOolongBright, honey, warm milkdaughter’s teaGingerbread Man 20222025-03-26NPuer - RipePuery, but a little uninterestingwhite2teaWaffles 20212025-03-22YPuer - RipeSweet, woody, portywhite2teaPretty Girls 20222025-03-21YPuer - RipeMolassis, barnwhite2teaLumberslut 20222025-03-17YPuer - RipeForrest, musty, wood, mushroomwhite2teaImperial Mojiang Golden Bud Yunnan Black Tea2025-03-16NBlackChocolate smell - unsure on tasteyunnan sourcingImperial Grade Silver Needle White Tea of Jinggu2025-03-16YWhiteVery floral and niceyunnan sourcingGolden Horse 8685 Ripe Tea in Tangerine2025-03-16NPuer - Ripea little one note, but the tangerine smell is niceyunnan sourcingFirst Flush “Mao Feng” Yunnan Green Tea2025-03-16NGreena little boringyunnan sourcingCompetition Grade Jin Jun Mei Black Tea2025-03-16YBlackchocolatey smooth - delicious!yunnan sourcingClassic Laoshan Green Tea from Shandong2025-03-16YGreendaily drinker, vegetal and a bit milkyyunnan sourcingAnxi “Hairy Crab” Mao Xie Fujian Oolong Tea2025-03-16NOolongvery green, not too interestingyunnan sourcing13 Years Aged Da Hong Pao Rock Oolong Tea2025-03-16YOolongearthy, roasty, a little sweetneeds a little more leaf and high tempyunnan sourcingImperial Dragon Well Tea From Zhejiang2025-03-16YGreenSomewhat acidic and no tannins. Very bright and vegetallook at instructions on websiteyunnan soucingMistle 20232025-03-16NBlackreally nice deep and bright, but not too much charactershorter brew timeswhite2teaCamphornought 2022 Mini2025-03-16YPuer - Ripewoody, smokey, boldwhite2teaBlood Moon 20242025-03-16NOolonga little boring, a little fruitywhite2teaAnhua Tianjian 20152025-03-16YHeichaEarthy and brightwhite2teaJade Red Oolong Tea2025-03-16NOolongA little boringguy on messengerJade Oolong Tea2025-03-16NOolongReally nice sweet smell, slightly sweet potato. But not interesting drinkguy on messengerDry Berry Ruby Oolong2025-03-16YOolongmilky berry-y, yummydaughter’s tea\n\nold.reddit.com/r/tea/comments/1h5t1m7/what_teas_have_you_purchased_in_the_last_week/\nteadb.org/white2tea/\nold.reddit.com/r/puer/comments/1hgaeqw/you_have_120_which_white2tea_shengs_are_you_buying/\nwhite2tea.com/pages/white2tea-tea-club-faq\nold.reddit.com/r/tea/comments/q84dgs/white_tea_recommendations/\nold.reddit.com/r/tea/comments/18ey0dj/recommendations_for_online_vendors_of_chinese_tea/\nold.reddit.com/r/tea/comments/sa9nue/white_teas_wanted/\nold.reddit.com/r/puer/comments/1ghh0va/favorite_tea_from_w2t/\nold.reddit.com/r/tea/comments/x36miv/ive_seen_a_lot_of_posts_where_w2t_is_getting/\nRemaining White2tea\nRipe Pu’er (Shou)\n\nAgeless Phase 2024\nCaledonia 2024\nLumber 2023\nLumber 2024\nPretty Girls 2021\nRed Loon 2023\nTale Chaser 2022 (drinks like aged shou)\n\nRaw Pu’er (Sheng)\n\nBiscuits 2024\nFirebat 2023 (smoked sheng)\nHypnotrain 2022\nTihkal 2024\n\nWhite Tea\n(includes charcoal-roasted &amp; moonlight styles)\n\nCharing Cross 2024 (charcoal-roasted)\nTiltshift 2024 (moonlight / shade-dried)\nGongmei 2019\n\nBlack Tea\n\nScrye 2022\nSunskate 2021 (lightly oxidised, borderline oolong)\n\nWhite2Tea Purchases\n\nAgeless Phase 2024\nAnhua Tianjian 2015\nAnhua Tianjian 2021\nBellwether 2024\nBig O V3 2023\nBiscuits 2024\nBlood Moon 2024\nCacao 80 2024\nCaledonia 2024\nCamphornought 2022\nCharing Cross 2024\nDark Peony 2024\nDitch Pike 2024\nDrills and Jeans 2025\nDualist 2022\nDualist 2024\nEn Passant 2023\nFirebat 2023\nGingerbread Man 2022\nGongmei 2019\nHypnotrain 2022\nInjured Coast 2022\nJonia 2025\nKarst 2023\nLa Sombra 2023\nLapsun 2023\nLumber 2022\nLumber 2023\nLumber 2024\nMistle 2023\nMoon Bear 2024\nNuo Xiang Shu 2003\nOrientalism and the Generated Image 2024\nPredawn Dark 2023\nPretty Girls 2021\nPretty Girls 2022\nReading Room 2023\nRectrix 2022\nRed Loon 2023\nSchedule White 2024\nScrye 2022\nShotgun Shack 2024\nSilver Fox 2024\nSmokeshou 2021\nSnowflake Dancong (no year)\nSun Fu 2018\nSunskate 2021\nTale Chaser 2022\nTheophilus 2024\nTihkal 2024\nTiltshift 2024\nWaffles 2021\n","date":"2025-10-15T17:01:02.621Z"},"recipes":{"slug":"recipes","filePath":"🍲 Recipes.md","title":"🍲 Recipes","links":["blog/On-Good-Vegan-Recipes","blog/Cooking-Techniques","zSystem/Assets/Besara.pdf","zSystem/Assets/CauliflowerSoup.pdf","zSystem/Assets/ChannaMasala.pdf","zSystem/Assets/Compote.pdf","zSystem/Assets/EzogelinCorbasi.pdf","zSystem/Assets/Goulash.pdf","zSystem/Assets/HunanSesameEggplant.pdf","zSystem/Assets/KimchiJigae.pdf","zSystem/Assets/MapoTofu.pdf","zSystem/Assets/MisoSoup.pdf","zSystem/Assets/MushroomKorma.pdf","zSystem/Assets/MushroomMisoRisotto.pdf","zSystem/Assets/NasuDengaku.pdf","zSystem/Assets/PastaAllaItsi.pdf","zSystem/Assets/PumpkinMasala.pdf","zSystem/Assets/Ragu.pdf","zSystem/Assets/TomatoSoup.pdf"],"tags":["recipes"],"content":"Here are my workshopped vegan recipes.\nQuite annoyingly, most available vegan recipes are bad. Feel free to my rant about it: On Good Vegan Recipes\nHere is a list of useful Cooking Techniques\nTo follow my recipes:\n\nThe ingredients list is a shopping list, ignore it once you’ve started cooking.\nTo improve time efficiency, prep and cooking steps are interspersed in each other. While you’re waiting for mushrooms to cook you should really be doing the next prep step.\nIf some steps are labelled as a ‘group’, it means to combine them in the same vessel and they’ll all be added to the dish together.\nRecipes are usually made for the minimum possible quantity. Scale-up as necessary.\nBuy a bag of MSG and add it to everything, you coward.\n\nPlease contact me for any questions or suggested improvements.\nRecipe List\nBesara (Green Pea Dip)\nCauliflower Soup\nChanna Masala (Chickpea Curry)\nCompote\nEzogelin Çorbasi (Lentil soup)\nGoulash\nHunan Sesame Eggplant\nKimchi Jigae\nMapo Tofu\nMiso Soup\nMushroom Korma\nMushroom Miso Risotto\nNasu Dengaku (Miso glazed eggplant)\nPasta alla Itsi\nPumpkin Masala\nRagù\nTomato Soup","date":"2025-10-15T17:01:02.666Z"},"movieshelf":{"slug":"movieshelf","filePath":"🎬 MovieShelf.md","title":"🎬 MovieShelf","links":[],"tags":[],"content":"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPosterTitleDirectorGenre⭐Adaptation.Spike JonzeComedy, Drama⭐The BrutalistBrady CorbetDrama⭐Beau Is AfraidAri AsterComedy, Drama, Horror⭐In BrugesMartin McDonaghComedy, Crime, Drama⭐Bo Burnham: InsideBo BurnhamDocumentary, Comedy, Drama⭐World of Tomorrow Episode Two: The Burden of Other People’s ThoughtsDon HertzfeldtAnimation, Short, Comedy⭐The Pervert’s Guide to IdeologySophie FiennesDocumentary⭐Uncut GemsBenny Safdie, Josh SafdieCrime, Drama, Thriller⭐World of TomorrowDon HertzfeldtAnimation, Short, Comedy⭐The Killing of a Sacred DeerYorgos LanthimosDrama, Horror, Mystery⭐The LobsterYorgos LanthimosDrama, Romance, Sci-Fi⭐A Serious ManEthan Coen, Joel CoenComedy, Drama⭐Everything Is IlluminatedLiev SchreiberComedy, Drama⭐ParasiteBong Joon HoDrama, Thriller⭐Allegro non troppoBruno BozzettoAnimation, Comedy, Fantasy⭐Grave of the FirefliesIsao TakahataAnimation, Drama, War⭐Jacqueline Novak: Get on Your KneesNatasha LyonneDocumentary, Comedy⭐Anatomy of a FallJustine TrietCrime, Drama, Thriller⭐Poor ThingsYorgos LanthimosComedy, Drama, Romance⭐Mary and MaxAdam ElliotAnimation, Comedy, Drama👍Caught by the TidesJia Zhang-keDrama👍TombstoneGeorge P. CosmatosBiography, Drama, History👍The SubstanceCoralie FargeatDrama, Horror, Sci-Fi👍AnoraSean BakerComedy, Drama, Romance👍Baby DriverEdgar WrightAction, Crime, Drama👍Bardo: False Chronicle of a Handful of TruthsAlejandro G. IñárrituComedy, Drama👍The FarewellLulu WangComedy, Drama👍Princess MononokeHayao MiyazakiAnimation, Adventure, Fantasy👍Birdman or (The Unexpected Virtue of Ignorance)Alejandro G. IñárrituComedy, Drama👍Everything Everywhere All at OnceDaniel Kwan, Daniel ScheinertAction, Adventure, Comedy👍The IrishmanMartin ScorseseBiography, Crime, Drama👍Léon: The ProfessionalLuc BessonAction, Crime, Drama👍WhiplashDamien ChazelleDrama, Music👍The Death of StalinArmando IannucciComedy, Drama, History👍The Grand Budapest HotelWes AndersonAdventure, Comedy, Crime👍Four LionsChristopher MorrisComedy, Crime, Drama👍Vampire’s KissRobert BiermanComedy, Crime, Fantasy👍What We Do in the ShadowsJemaine Clement, Taika WaititiComedy, Horror👍Isle of DogsWes AndersonAnimation, Adventure, Comedy👍The Trial of the Chicago 7Aaron SorkinDrama, History, Thriller👍The Boy and the HeronHayao MiyazakiAnimation, Adventure, Drama👍The Iron GiantBrad BirdAnimation, Action, Adventure👍Master and Commander: The Far Side of the WorldPeter WeirAction, Adventure, Drama🤷Citizen KaneOrson WellesDrama, Mystery🤷Swiss Army ManDaniel Kwan, Daniel ScheinertComedy, Drama, Fantasy🤷Airplane!Jim Abrahams, David Zucker, Jerry ZuckerComedy🤷AnnihilationAlex GarlandAdventure, Drama, Horror🤷Ex MachinaAlex GarlandDrama, Sci-Fi, Thriller🤷HerSpike JonzeDrama, Romance, Sci-Fi🤷The Banshees of InisherinMartin McDonaghComedy, Drama🤷Three Billboards Outside Ebbing, MissouriMartin McDonaghComedy, Crime, Drama🤷The Big ShortAdam McKayBiography, Comedy, Drama🤷The MasterPaul Thomas AndersonDrama, History🤷The Wolf of Wall StreetMartin ScorseseBiography, Comedy, Crime🤷Memoir of a SnailAdam ElliotAnimation, Drama🤷The CastleRob SitchComedy, Drama🤷About TimeRichard CurtisComedy, Drama, Fantasy🤷Dream ScenarioKristoffer BorgliComedy, Drama, Fantasy🤷Kinds of KindnessYorgos LanthimosComedy, Drama, Horror🤷The Rescuers Down UnderHendel Butoy, Mike GabrielAnimation, Adventure, Comedy👎KimiSteven SoderberghCrime, Drama, Mystery👎Juror #2Clint EastwoodCrime, Drama, Mystery👎ConclaveEdward BergerDrama, Thriller👎A Different ManAaron SchimbergComedy, Drama, Thriller👎ProblemistaJulio TorresComedy👎A Real PainJesse EisenbergComedy, Drama👎Civil WarAlex GarlandAction, Adventure, Thriller👎Next Goal WinsTaika WaititiComedy, Drama, SportAmerican FictionCord JeffersonComedy, DramaDownfallOliver HirschbiegelBiography, Drama, HistoryHeathersMichael LehmannComedy, CrimeBabyteethShannon MurphyComedy, Drama, MusicCloud AtlasTom Tykwer, Lana Wachowski, Lilly WachowskiDrama, Mystery, Sci-FiForce MajeureRuben ÖstlundComedy, DramaChicken RunPeter Lord, Nick ParkAnimation, Adventure, ComedyChicken Run: Dawn of the NuggetSam Fell, Jeff NewittAnimation, Adventure, ComedyUp in the AirJason ReitmanComedy, Drama, RomanceHolesAndrew DavisAdventure, Comedy, DramaStop Making SenseJonathan DemmeDocumentary, MusicAntzEric Darnell, Tim Johnson, Lawrence GutermanAnimation, Adventure, ComedyThe Worst Person in the WorldJoachim TrierComedy, Drama, RomanceL’ArgentRobert BressonCrime, DramaTangerinesZaza UrushadzeDrama, WarHow to Blow Up a PipelineDaniel GoldhaberAction, Crime, DramaThe Devil, ProbablyRobert BressonDramaThe Garden of the Finzi-ContinisVittorio De SicaDrama, History, WarHe Died with a Felafel in His HandRichard LowensteinComedy, RomanceHidalgoJoe JohnstonAction, Adventure, BiographySlaughterhouse-FiveGeorge Roy HillComedy, Drama, Sci-FiGattacaAndrew NiccolDrama, Sci-Fi, ThrillerNever Let Me GoMark RomanekDrama, RomanceDrive My CarRyûsuke HamaguchiDramaBrazilTerry GilliamDrama, Sci-Fi, ThrillerHouseboundGerard JohnstoneComedy, Horror, MysteryThe Baader Meinhof ComplexUli EdelAction, Biography, CrimeThe Raspberry ReichBruce La BruceComedy, Drama, RomancePride &amp; PrejudiceJoe WrightDrama, RomanceChildren of MenAlfonso CuarónDrama, Sci-Fi, ThrillerPhantom ThreadPaul Thomas AndersonDrama, RomanceMichael ClaytonTony GilroyCrime, Drama, MysteryIn the Mood for LoveWong Kar-WaiDrama, RomanceThere Will Be BloodPaul Thomas AndersonDramaChildren of GodKareem MortimerDramaThe Zone of InterestJonathan GlazerDrama, History, WarA SeparationAsghar FarhadiDramaBoyhoodRichard LinklaterDramaY tu mamá tambiénAlfonso CuarónDramaA ProphetJacques AudiardCrime, DramaThe Lives of OthersFlorian Henckel von DonnersmarckDrama, Mystery, ThrillerYi YiEdward YangDrama, RomanceUnder the SkinJonathan GlazerDrama, Horror, MysteryCarolTodd HaynesDrama, RomanceLet the Right One InTomas AlfredsonDrama, Fantasy, HorrorThe Florida ProjectSean BakerDramaFrances HaNoah BaumbachComedy, Drama, RomanceO Brother, Where Art Thou?Joel Coen, Ethan CoenAdventure, Comedy, CrimeIndus BluesJawad SharifDocumentary, MusicalHappinessTodd SolondzComedy, DramaWorld of Tomorrow Episode Three: The Absent Destinations of David PrimeDon HertzfeldtAnimation, Short, Comedy","date":"2025-10-15T17:01:02.732Z"},"bookshelf":{"slug":"bookshelf","filePath":"📖 BookShelf.md","title":"📖 BookShelf","links":[],"tags":[],"content":"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCoverTitleAuthorCategory⭐MetamorphosisFranz KafkaFiction⭐Slaughterhouse-fiveKurt VonnegutCensorship⭐The Deficit MythStephanie KeltonBusiness &amp; Economics⭐Bullshit JobsDavid GraeberSocial Science👍The People’s Republic of WalmartLeigh Phillips, Michal RozworskiPolitical Science👍If We BurnVincent BevinsHistory👍Manufacturing ConsentEdward S. Herman, Noam ChomskySocial Science👍Thinking in SystemsDonella MeadowsBusiness &amp; Economics👍Developer HegemonyErik DietrichBusiness &amp; Economics👍Drive Your Plow Over the Bones of the DeadOlga TokarczukFiction👍A Psalm for the Wild-BuiltBecky ChambersFiction🤷The Rest Is NoiseAlex RossMusic🤷The Iliad of HomerHomer[]👎Against EmpathyPaul BloomPsychologyBad News from VenezuelaAlan MacleodSocial ScienceThe Dawn of EverythingDavid Graeber, David WengrowSocial ScienceDavid Foster Wallace’s Infinite JestStephen J. BurnLiterary CriticismThe Emperor’s New DrugsIrving KirschPsychologyThe Myth of Mental IllnessThomas S. SzaszPsychologyUntangling SelfAndrew OlendzkiReligionGod &amp; Golem, Inc.Norbert WienerPhilosophyPachinko (National Book Award Finalist)Min Jin LeeFictionThe Value of EverythingMariana MazzucatoBusiness &amp; EconomicsTomorrow, and Tomorrow, and TomorrowGabrielle ZevinFictionThe Ecology of FreedomMurray BookchinHistoryHopscotchJulio CortázarFictionThe FountainheadAyn RandFictionThe Master &amp; MargaritaMikhail BulgakovFictionThe Wizard and the ProphetCharles C. MannScienceAbolish RentTracy Rosenthal, Leonardo VilchisSocial ScienceCan’t Pay, Won’t PayCollective DebtSocial ScienceCapitalist RealismMark FisherPolitical ScienceNapoleon’s ButtonsPenny Le Couteur, Jay BurresonScienceEucalyptusMurray BailFictionGoatManThomas ThwaitesBiography &amp; AutobiographyThe SonglinesBruce ChatwinTravelWhite NoiseDon DeLilloFictionOn Murder Considered as one of the Fine ArtsThomas de QuinceyFictionRamping Your BrandJames F. RichardsonBusiness &amp; EconomicsUnder a White SkyElizabeth KolbertSciencePedro PáramoJuan Rulfo, Josephine Sacabo, Margaret Sayers PedenFictionThe Plain in FlamesJuan RulfoFictionConversation in the CathedralMario Vargas LlosaFictionHow the War Was WonPhillips Payson O’BrienHistoryEconomics Without IllusionsJoseph HeathBusiness &amp; EconomicsThank You for Arguing, Fourth Edition (Revised and Updated)Jay HeinrichsLanguage Arts &amp; DisciplinesUnderstanding MediaMarshall McLuhan[]Why We’re Getting PoorerCahal MoranBusiness &amp; EconomicsHealth CommunismBeatrice Adler-Bolton, Artie VierkantPolitical ScienceAgainst PlatformsMike PepiSocial ScienceThe Limits of GrowthD. H. Meadows[]Neoliberalism’s DemonsAdam KotskoPolitical ScienceThe CrowdGustave Le BonFictionThe Jakarta MethodVincent BevinsPolitical ScienceLiberalismDomenico LosurdoPolitical ScienceWho Are We Now?Blaise Aguera y ArcasComputersMeat PlanetBenjamin Aldes WurgaftSocial ScienceThe Chapo Guide to RevolutionChapo Trap House, Felix Biederman, Matt Christman, Brendan James, Will Menaker, Virgil TexasHumorSelling Social JusticeJennifer C. PanSocial ScienceAgainst the WebMichael BrooksPhilosophyChangeDamon CentolaSocial ScienceHow Behavior SpreadsDamon CentolaSocial ScienceHere I AmJonathan Safran FoerFictionSimulacra and SimulationJean BaudrillardArtAs a Driven LeafMilton SteinbergFictionFoundationIsaac AsimovLife on other planetsA Dog’s HeartMikhail BulgakovFictionProofs and RefutationsImre LakatosMathematics","date":"2025-10-15T17:01:02.783Z"},"tvshelf":{"slug":"tvshelf","filePath":"📺 TVShelf.md","title":"📺 TVShelf","links":[],"tags":[],"content":"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRatingPosterTitleWriter⭐Avatar: The Last AirbenderMichael Dante DiMartino, Bryan Konietzko⭐BoJack HorsemanRaphael Bob-Waksberg⭐Limmy’s Show!Brian Limond⭐Indian MatchmakingN/A⭐AtlantaDonald Glover⭐Arrested DevelopmentMitchell Hurwitz⭐You Can’t Ask ThatN/A⭐Love on the SpectrumN/A⭐How to with John WilsonN/A⭐Nathan for YouNathan Fielder, Michael Koman⭐SuccessionJesse Armstrong⭐WatchmenN/A⭐UnorthodoxAnna Winger⭐Better Call SaulVince Gilligan, Peter Gould⭐FleabagPhoebe Waller-Bridge⭐LouieLouis C.K.⭐Los EspookysFred Armisen, Ana Fabrega, Julio Torres⭐Peep ShowJesse Armstrong, Sam Bain, Andrew O’Connor👍America’s Next Top ModelKen Mok, Tyra Banks, Kenya Barris👍Aunty Donna’s Big Ol’ House of FunAunty Donna👍EasyJoe Swanberg👍Russian DollLeslye Headland, Natasha Lyonne, Amy Poehler👍The Great British Baking ShowN/A👍MisfitsHoward Overman👍Master of NoneAziz Ansari, Alan Yang👍I Think You Should Leave with Tim RobinsonZach Kanin, Tim Robinson👍RakePeter Duncan, Richard Roxburgh, Charles Waterstreet👍MaidMolly Smith Metzler👍Carol &amp; The End of the WorldDan Guterman👍On Becoming a God in Central FloridaRobert Funke, Matt Lutsky👍Why Women KillMarc Cherry👍Flight of the ConchordsJames Bobin, Jemaine Clement, Bret McKenzie👍Please Like MeN/A👍Breaking BadVince Gilligan👍Killing EvePhoebe Waller-Bridge👍FargoNoah Hawley👍Curb Your EnthusiasmLarry David🤷Alice in BorderlandHaro Aso🤷Big MouthJennifer Flackett, Andrew Goldberg, Nick Kroll🤷BridgertonChris Van Dusen🤷DetroitersZach Kanin, Joe Kelly, Sam Richardson🤷LovesickTom Edge🤷SeinfeldLarry David, Jerry Seinfeld🤷Stranger ThingsMatt Duffer, Ross Duffer🤷The Queen’s GambitScott Frank, Allan Scott🤷Your HonorPeter Moffat🤷UtopiaSanto Cilauro, Tom Gleisner, Rob Sitch🤷Love, Death &amp; RobotsTim Miller🤷After LifeRicky Gervais🤷Sex EducationLaurie Nunn🤷The Eric Andre ShowEric André🤷Black MirrorCharlie Brooker👎FBoy IslandElan Gale👎Jewish MatchmakingN/A👎KaosCharlie Covell👎The Umbrella AcademySteve Blackman, Jeremy Slater👎WednesdayAlfred Gough, Miles Millar👎YouGreg Berlanti, Sera Gamble👎3 Body ProblemDavid Benioff, D.B. Weiss, Alexander Woo👎Kim’s ConvenienceN/A👎DisenchantmentMatt Groening, Josh Weinstein👎Sex and the CityDarren StarMr. Show with Bob and DavidDavid Cross, Bob OdenkirkThe Dana Carvey ShowDana Carvey, Robert SmigelThe CurseNathan Fielder, Benny SafdieUnder the Banner of HeavenDustin Lance BlackCouples TherapyN/A","date":"2025-10-15T17:01:02.826Z"}}